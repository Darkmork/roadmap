{
  "VPI89s-m885r2YrXjYxdd": {
    "title": "Desarrollo Backend Básico",
    "description": "Antes de comenzar a aprender cómo construir agentes de IA, te recomendamos tener un conocimiento básico de desarrollo Backend. Esto incluye, como mínimo, conocimiento de lenguajes de programación, interacción con bases de datos y conceptos básicos de APIs.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Introducción al lado del servidor",
        "url": "https://developer.mozilla.org/en-US/docs/Learn/Server-side/First_steps/Introduction",
        "type": "article"
      },
      {
        "title": "¿Qué es una API REST? - Red Hat",
        "url": "https://www.redhat.com/en/topics/api/what-is-a-rest-api",
        "type": "article"
      },
      {
        "title": "¿Qué es una base de datos? - Oracle",
        "url": "https://www.oracle.com/database/what-is-database/",
        "type": "article"
      }
    ]
  },
  "McREk2zHOlIrqbGSKbX-J": {
    "title": "Uso de Git y Terminal",
    "description": "Git y la terminal son herramientas clave para los agentes de IA y los desarrolladores. Git te permite rastrear cambios en el código, trabajar con ramas y colaborar de forma segura con otros. Almacena instantáneas de tu trabajo para que puedas deshacer errores o fusionar ideas. La terminal (línea de comandos) te permite moverte entre archivos, ejecutar programas, configurar servidores y controlar herramientas como Git rápidamente sin una GUI.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Conceptos básicos de Git",
        "url": "https://git-scm.com/doc",
        "type": "article"
      },
      {
        "title": "Introducción a la Terminal",
        "url": "https://ubuntu.com/tutorials/command-line-for-beginners#1-overview",
        "type": "article"
      },
      {
        "title": "Curso Intensivo de Conceptos Básicos de Git y Terminal (YouTube)",
        "url": "https://www.youtube.com/watch?v=HVsySz-h9r4",
        "type": "video"
      }
    ]
  },
  "QtTwecLdvQa8pgELJ6i80": {
    "title": "Conocimiento de API REST",
    "description": "Una **API REST** (Transferencia de Estado Representacional) es un estilo arquitectónico para diseñar aplicaciones en red. En los agentes de IA, las API REST permiten la comunicación entre el agente y los sistemas externos, facilitando el intercambio e integración de datos. El agente puede usar API REST para recuperar datos de fuentes externas, enviar datos a sistemas externos e interactuar con otros agentes o servicios de IA. Esto proporciona una forma flexible y escalable de integrarse con diversos sistemas, permitiendo al agente acceder a una amplia gama de datos y servicios. Las API REST en agentes de IA admiten una variedad de funciones, incluyendo la recuperación de datos, el envío de datos y la interacción del sistema. Desempeñan un papel crucial en la facilitación de la comunicación entre los agentes de IA y los sistemas externos, convirtiéndolos en un componente fundamental de la arquitectura de agentes de IA.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué es una API RESTful? - API RESTful Explicada - AWS",
        "url": "https://aws.amazon.com/what-is/restful-api/",
        "type": "article"
      },
      {
        "title": "¿Qué es una API REST? Ejemplos, Usos y Desafíos",
        "url": "https://blog.postman.com/rest-api-examples/",
        "type": "article"
      }
    ]
  },
  "ZF5_5Y5zqa75Ov22JACX6": {
    "title": "Modelos Transformer y LLMs",
    "description": "Los modelos Transformer son un tipo de red neuronal que lee datos de entrada—como palabras en una oración—todos a la vez en lugar de una pieza a la vez. Usan “atención” para encontrar qué partes de la entrada son más importantes para cada otra parte. Esto les permite aprender patrones en el lenguaje muy bien. Cuando un transformer ha sido entrenado con un conjunto muy grande de texto, lo llamamos un Modelo de Lenguaje Grande (LLM). Un LLM puede responder preguntas, escribir texto, traducir idiomas y programar porque ha visto muchos ejemplos durante el entrenamiento. Los agentes de IA usan estos modelos como sus “cerebros”. Alimentan tareas o indicaciones al LLM, obtienen texto o planes de vuelta, y luego actúan sobre esos resultados. Esta estructura ayuda a los agentes a comprender objetivos, dividirlos en pasos y ajustarse según la retroalimentación, haciéndolos útiles para chatbots, ayudantes de investigación y herramientas de automatización.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Explorando Modelos de IA de Código Abierto: LLMs y Arquitecturas Transformer",
        "url": "https://llmmodels.org/blog/exploring-open-source-ai-models-llms-and-transformer-architectures/",
        "type": "article"
      },
      {
        "title": "Comparación entre Modelos Transformer y LLM",
        "url": "https://www.restack.io/p/transformer-models-answer-vs-llm-cat-ai",
        "type": "article"
      },
      {
        "title": "Cómo Funcionan los LLMs Transformer",
        "url": "https://www.deeplearning.ai/short-courses/how-transformer-llms-work/",
        "type": "article"
      }
    ]
  },
  "GAjuWyJl9CI1nqXBp6XCf": {
    "title": "Tokenización",
    "description": "La tokenización es el paso donde el texto crudo se divide en pequeñas piezas llamadas tokens, y a cada token se le asigna un número único. Un token puede ser una palabra completa, parte de una palabra, un signo de puntuación o incluso un espacio. La lista de todos los tokens posibles es el vocabulario del modelo. Una vez que el texto se convierte en estos tokens numerados, el modelo puede buscar una incrustación para cada número y comenzar sus cálculos. Al trabajar con tokens en lugar de oraciones completas, el modelo mantiene el tamaño de entrada estable y puede manejar palabras nuevas o raras dividiéndolas en sub-piezas familiares. Después de que el modelo termina su trabajo, los tokens numerados se convierten de nuevo en texto a través del mismo mapa de vocabulario, permitiendo al usuario leer el resultado.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Explicando los Tokens — el Lenguaje y la Moneda de la IA",
        "url": "https://blogs.nvidia.com/blog/ai-tokens-explained/",
        "type": "article"
      },
      {
        "title": "¿Qué es la Tokenización? Tipos, Casos de Uso, Implementación",
        "url": "https://www.datacamp.com/blog/what-is-tokenization",
        "type": "article"
      }
    ]
  },
  "dyn1LSioema-Bf9lLTgUZ": {
    "title": "Ventanas de Contexto",
    "description": "Una ventana de contexto es el fragmento de texto que un modelo de lenguaje grande puede leer de una vez. Se mide en tokens, que son piezas de palabras. Si un modelo tiene una ventana de 4,000 tokens, solo puede “ver” hasta unas 3,000 palabras antes de que deba olvidar o acortar partes anteriores. Los nuevos tokens empujan a los antiguos, como una ventana deslizante que se mueve sobre el texto. El tamaño de la ventana establece límites estrictos sobre cuán largo puede ser un prompt, historial de chat o documento. Una ventana pequeña te obliga a mantener las entradas cortas o dividirlas, mientras que una ventana grande permite que el modelo siga historias más largas y retenga más hechos. Elegir el tamaño de ventana correcto equilibra el costo, la velocidad y la cantidad de detalles que el modelo puede tener en cuenta a la vez.\n\nNuevas técnicas, como la generación aumentada por recuperación (RAG) y los transformers de contexto largo (por ejemplo, Claude 3, Gemini 1.5), tienen como objetivo extender el contexto utilizable sin alcanzar directamente los límites del modelo.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué es una Ventana de Contexto en IA?",
        "url": "https://www.ibm.com/think/topics/context-window",
        "type": "article"
      },
      {
        "title": "Escalando Modelos de Lenguaje con Generación Aumentada por Recuperación (RAG)",
        "url": "https://arxiv.org/abs/2005.11401",
        "type": "article"
      },
      {
        "title": "Contexto Largo en Modelos de Lenguaje - Claude 3 de Anthropic",
        "url": "https://www.anthropic.com/news/claude-3-family",
        "type": "article"
      }
    ]
  },
  "1fiWPBV99E2YncqdCgUw2": {
    "title": "Precios Basados en Tokens",
    "description": "El precio basado в tokens es cómo muchos servicios de modelos de lenguaje cobran por el uso. Un token es un pequeño fragmento de texto, aproximadamente cuatro caracteres o parte de una palabra. El servicio cuenta cada token que entra en el modelo (tu prompt) y cada token que sale (la respuesta). Luego multiplica este total por un precio listado por cada mil tokens. Algunos planes establecen un precio para los tokens de entrada y un precio mayor o menor para los tokens de salida. Debido a que la factura crece con cada token, los usuarios a menudo acortan los prompts, eliminan palabras adicionales o limitan la longitud de la respuesta para gastar menos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Explicando los Tokens — el Lenguaje y la Moneda de la IA",
        "url": "https://blogs.nvidia.com/blog/ai-tokens-explained/",
        "type": "article"
      },
      {
        "title": "¿Qué Son los Tokens de IA?",
        "url": "https://methodshop.com/what-are-ai-tokens/",
        "type": "article"
      },
      {
        "title": "Precios - OpenAI",
        "url": "https://openai.com/api/pricing/",
        "type": "article"
      }
    ]
  },
  "L1zL1GzqjSAjF06pIIXhy": {
    "title": "Temperatura",
    "description": "La temperatura es un ajuste que cambia cuán aleatoria o predecible es la salida de texto de un modelo de IA. El valor generalmente va de 0 a 1, a veces más alto. Una temperatura baja, cercana a 0, hace que el modelo elija la siguiente palabra más probable casi siempre, por lo que la respuesta es estable y segura, pero puede parecer aburrida o repetitiva. Una temperatura alta, como 0.9 o 1.0, permite al modelo explorar opciones de palabras menos probables, lo que puede dar respuestas frescas y creativas, pero también puede agregar errores o desviarse del tema. Al ajustar la temperatura, equilibras la confiabilidad y la creatividad para adaptarlas al objetivo de tu tarea.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Qué Significa la Temperatura en el Procesamiento del Lenguaje Natural y la IA",
        "url": "https://thenewstack.io/what-temperature-means-in-natural-language-processing-and-ai/",
        "type": "article"
      },
      {
        "title": "Temperatura LLM: Cómo Funciona y Cuándo Deberías Usarla",
        "url": "https://www.vellum.ai/llm-parameters/temperature",
        "type": "article"
      },
      {
        "title": "¿Qué es la Temperatura LLM? - IBM",
        "url": "https://www.ibm.com/think/topics/llm-temperature",
        "type": "article"
      },
      {
        "title": "Cómo los Ajustes de Temperatura Transforman las Respuestas de tu Agente de IA",
        "url": "https://docsbot.ai/article/how-temperature-settings-transform-your-ai-agents-responses",
        "type": "article"
      }
    ]
  },
  "z_N-Y0zGkv8_qHPuVtimL": {
    "title": "Penalización de Frecuencia",
    "description": "La penalización de frecuencia es un ajuste que le dice a un modelo de lenguaje: “Deja de repetirte”. A medida que el modelo escribe, realiza un seguimiento de cuántas veces ya ha usado cada palabra. Un valor positivo de penalización de frecuencia reduce la posibilidad de elegir una palabra nuevamente si se ha visto muchas veces en la respuesta actual. Esto ayuda a reducir bucles como “muy muy muy” o bloques largos que repiten la misma frase. Un valor de 0 desactiva la regla, mientras que números más altos hacen que el modelo evite las repeticiones con más fuerza. Si la penalización es demasiado alta, el texto puede omitir palabras comunes que aún son necesarias, por lo que a menudo se comienza bajo (por ejemplo, 0.2) y se ajusta. La penalización de frecuencia funciona junto con otros controles como la temperatura y top-p para dar forma a una salida que sea clara, variada y no aburrida.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Explicación de la Penalización de Frecuencia",
        "url": "https://docs.aipower.org/docs/ai-engine/openai/frequency-penalty",
        "type": "article"
      },
      {
        "title": "Entendiendo la Penalización de Frecuencia y la Penalización de Presencia",
        "url": "https://medium.com/@the_tori_report/understanding-frequency-penalty-and-presence-penalty-how-to-fine-tune-ai-generated-text-e5e4f5e779cd",
        "type": "article"
      }
    ]
  },
  "Vd8ycw8pW-ZKvg5WYFtoh": {
    "title": "Penalización de Presencia",
    "description": "La penalización de presencia es un ajuste que puedes modificar cuando le pides a un modelo de lenguaje grande que escriba. Empuja al modelo a elegir palabras que aún no ha usado. Cada vez que una palabra ya ha aparecido, el modelo recibe un pequeño recorte de puntuación por elegirla de nuevo. Una penalización más alta da recortes más grandes, por lo que el modelo busca nuevas palabras e ideas frescas. Una penalización más baja permite que el modelo reutilice palabras más a menudo, lo que puede ayudar con repeticiones como rimas o listas con viñetas. Ajustar este control te ayuda a dirigir la salida hacia una mayor variedad o una mayor consistencia.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Entendiendo la Penalización de Presencia y la Penalización de Frecuencia",
        "url": "https://medium.com/@pushparajgenai2025/understanding-presence-penalty-and-frequency-penalty-in-openai-chat-completion-api-calls-2e3a22547b48",
        "type": "article"
      },
      {
        "title": "¿Diferencia entre Penalizaciones de Frecuencia y Presencia?",
        "url": "https://community.openai.com/t/difference-between-frequency-and-presence-penalties/2777",
        "type": "article"
      },
      {
        "title": "Parámetros LLM Explicados: Una Guía Práctica con Ejemplos",
        "url": "https://learnprompting.org/blog/llm-parameters",
        "type": "article"
      }
    ]
  },
  "icbp1NjurQfdM0dHnz6v2": {
    "title": "Top-p",
    "description": "Top-p, también llamado muestreo de núcleo, es un ajuste que guía cómo un LLM elige su siguiente palabra. El modelo lista muchas palabras posibles y las ordena por probabilidad. Luego encuentra el grupo más pequeño de palabras principales cuya probabilidad combinada suma el valor p elegido, como 0.9. Solo las palabras dentro de este grupo permanecen en la carrera; el resto se descartan. El modelo elige una palabra del grupo conservado al azar, ponderada por sus probabilidades originales. Un p más bajo mantiene solo las palabras muy probables, por lo que la salida es más segura y enfocada. Un p más alto permite palabras menos probables, agregando sorpresa y creatividad pero también más riesgo de error.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Muestreo de Núcleo",
        "url": "https://nn.labml.ai/sampling/nucleus.html",
        "type": "article"
      },
      {
        "title": "Técnicas de Muestreo en Modelos de Lenguaje Grandes (LLMs)",
        "url": "https://medium.com/@shashankag14/understanding-sampling-techniques-in-large-language-models-llms-dfc28b93f518",
        "type": "article"
      },
      {
        "title": "Temperatura, top_p y top_k para respuestas de chatbot",
        "url": "https://community.openai.com/t/temperature-top-p-and-top-k-for-chatbot-responses/295542",
        "type": "article"
      }
    ]
  },
  "K0G-Lw069jXUJwZqHtybd": {
    "title": "Criterios de Detención",
    "description": "Los criterios de detención le indican al modelo de lenguaje cuándo dejar de escribir más texto. Sin ellos, el modelo podría seguir agregando palabras indefinidamente, perder tiempo o exceder el punto que nos interesa. Las reglas comunes incluyen un número máximo de tokens, un token especial de fin de secuencia o una cadena personalizada como `“\\n\\n”`. También podemos detenernos cuando la respuesta comienza a repetirse o alcanza una puntuación que significa que está fuera de tema. Buenas reglas de detención ahorran costos, aceleran las respuestas y evitan contenido sin sentido o inseguro.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Definición de Criterios de Detención en Modelos de Lenguaje Grandes",
        "url": "https://www.metriccoders.com/post/defining-stopping-criteria-in-large-language-models-a-practical-guide",
        "type": "article"
      },
      {
        "title": "Criterios de Detención para el Algoritmo de Árbol de Decisión y Gráficos de Árbol",
        "url": "https://aieagle.in/stopping-criteria-for-decision-tree-algorithm-and-tree-plots/",
        "type": "article"
      }
    ]
  },
  "DSJAhQhc1dQmBHQ8ZkTau": {
    "title": "Modelos de Pesos Abiertos",
    "description": "Los modelos de pesos abiertos son redes neuronales cuyos parámetros entrenados, también llamados pesos, se comparten con todos. Cualquiera puede descargar los archivos, ejecutar el modelo, ajustarlo o construir herramientas sobre él. La licencia que viene con el modelo detalla lo que se te permite hacer. Algunas licencias son muy permisivas e incluso te permiten usar el modelo para trabajos comerciales. Otras solo permiten proyectos de investigación o personales. Debido a que los pesos son públicos, la comunidad puede inspeccionar cómo funciona el modelo, verificar sesgos y sugerir correcciones. Los pesos abiertos también reducen los costos, ya que los equipos no tienen que entrenar un modelo grande desde cero. Ejemplos conocidos incluyen BLOOM, Falcon y Llama 2.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "BLOOM BigScience",
        "url": "https://bigscience.huggingface.co/",
        "type": "article"
      },
      {
        "title": "Falcon LLM – Instituto de Innovación Tecnológica (TII)",
        "url": "https://falconllm.tii.ae/",
        "type": "article"
      },
      {
        "title": "Llama 2 – Anuncio Oficial de Meta",
        "url": "https://ai.meta.com/llama/",
        "type": "article"
      },
      {
        "title": "Hugging Face – Tabla de Clasificación de LLM Abiertos (Mejores Modelos Abiertos)",
        "url": "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard",
        "type": "article"
      },
      {
        "title": "EleutherAI – Colectivo de Investigación Abierta (GPT-Neo, GPT-J, etc.)",
        "url": "https://www.eleuther.ai/",
        "type": "article"
      }
    ]
  },
  "tJYmEDDwK0LtEux-kwp9B": {
    "title": "Modelos de Pesos Cerrados",
    "description": "Los modelos de pesos cerrados son sistemas de IA cuyos parámetros entrenados —los números que contienen lo que el modelo ha aprendido— no se comparten con el público. Puedes enviar prompts a estos modelos a través de un servicio en línea o un kit de software, pero no puedes descargar los pesos, inspeccionarlos o ajustarlos en tu propia computadora. La compañía propietaria del modelo mantiene el control y establece las reglas de uso, a menudo a través de API de pago o licencias estrictas. Este enfoque ayuda al propietario a proteger secretos comerciales, reducir el uso indebido y mantener un flujo de ingresos constante. La desventaja es menos libertad para los usuarios, costos más altos con el tiempo y capacidad limitada para auditar o adaptar el modelo. Ejemplos conocidos incluyen GPT-4, Claude y Gemini.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "LLMs de Código Abierto vs LLMs Cerrados",
        "url": "https://hatchworks.com/blog/gen-ai/open-source-vs-closed-llms-guide/",
        "type": "article"
      },
      {
        "title": "Comparación 2024 de LLMs de Código Abierto Vs Código Cerrado",
        "url": "https://blog.spheron.network/choosing-the-right-llm-2024-comparison-of-open-source-vs-closed-source-llms",
        "type": "article"
      },
      {
        "title": "GPT-4 de Open AI",
        "url": "https://openai.com/gpt-4",
        "type": "article"
      },
      {
        "title": "Claude",
        "url": "https://www.anthropic.com/claude",
        "type": "article"
      },
      {
        "title": "Gemini",
        "url": "https://deepmind.google/technologies/gemini/",
        "type": "article"
      }
    ]
  },
  "i2NE6haX9-7mdoV5LQ3Ah": {
    "title": "Respuestas Transmitidas vs No Transmitidas",
    "description": "Las respuestas transmitidas y no transmitidas describen cómo un agente de IA envía su respuesta al usuario. Con una respuesta transmitida, el agente comienza a enviar palabras tan pronto como las genera. El usuario ve crecer el texto en la pantalla en tiempo real. Esto se siente rápido y permite al usuario detener o cambiar la solicitud temprano. Es útil para respuestas largas y aplicaciones tipo chat.\n\nUna respuesta no transmitida espera hasta que toda la respuesta esté lista, luego la envía toda de una vez. Esto simplifica el código del lado del cliente y es más fácil de almacenar en caché o registrar, pero el usuario debe esperar más, especialmente para salidas grandes. Elegir entre los dos depende de la necesidad de velocidad, la longitud de la respuesta y cuán complejo quieres que sean el cliente y el servidor.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Respuestas Transmitidas en IA: Cómo se Generan las Salidas de IA en Tiempo Real",
        "url": "https://dev.to/pranshu_kabra_fe98a73547a/streaming-responses-in-ai-how-ai-outputs-are-generated-in-real-time-18kb",
        "type": "article"
      },
      {
        "title": "IA para Desarrolladores Web: Respuestas Más Rápidas con Transmisión HTTP",
        "url": "https://austingil.com/ai-for-web-devs-streaming/",
        "type": "article"
      },
      {
        "title": "Domina la API de OpenAI: Respuestas Transmitidas",
        "url": "https://www.toolify.ai/gpts/master-the-openai-api-stream-responses-139447",
        "type": "article"
      }
    ]
  },
  "N3yZfUxphxjiupqGpyaS9": {
    "title": "Modelos de Razonamiento vs Estándar",
    "description": "Los modelos de razonamiento dividen una tarea en pasos claros y siguen una línea de lógica, mientras que los modelos estándar dan una respuesta en un movimiento rápido. Un modelo de razonamiento podría escribir notas cortas, verificar cada nota y luego combinarlas para llegar a la respuesta final. Esto le ayuda a resolver problemas matemáticos, planificar acciones y detectar errores que la simple coincidencia de patrones pasaría por alto. Un modelo estándar depende de los patrones que aprendió durante el entrenamiento y, a menudo, adivina la siguiente palabra más probable. Eso funciona bien para chats cotidianos, resúmenes o hechos comunes, pero puede fallar en acertijos difíciles o tareas con muchas partes vinculadas. El razonamiento lleva más tiempo y potencia informática, pero brinda mayor precisión y hace que el agente sea más fácil de depurar porque puedes ver sus pasos de pensamiento. Muchos agentes de IA nuevos mezclan ambos estilos: usan el recuerdo rápido de patrones para partes simples y cambian al razonamiento paso a paso cuando un objetivo necesita una reflexión más profunda.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "ReAct: Sinergizando Razonamiento y Actuación en Modelos de Lenguaje",
        "url": "https://react-lm.github.io/",
        "type": "article"
      },
      {
        "title": "Sistemas ReAct: Mejorando LLMs con Razonamiento y Acción",
        "url": "https://learnprompting.org/docs/agents/react",
        "type": "article"
      }
    ]
  },
  "5OW_6o286mj470ElFyJ_5": {
    "title": "Ajuste Fino vs Ingeniería de Prompts",
    "description": "El ajuste fino y la ingeniería de prompts son dos formas de obtener mejores resultados de un modelo de lenguaje. El ajuste fino significa entrenar un modelo existente aún más con tus propios ejemplos para que se adapte a tareas específicas. Necesita datos adicionales, potencia informática y tiempo, pero crea modelos profundamente especializados. La ingeniería de prompts, por el contrario, deja el modelo sin cambios y se enfoca en elaborar mejores instrucciones o ejemplos en el propio prompt. Es más rápido, más barato y más seguro cuando no hay datos personalizados disponibles. El ajuste fino se adapta a las necesidades profundas del dominio; la ingeniería de prompts se ajusta al control rápido y la creación de prototipos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Ajuste Fino de OpenAI",
        "url": "https://platform.openai.com/docs/guides/fine-tuning",
        "type": "article"
      },
      {
        "title": "Guía de Ingeniería de Prompts",
        "url": "https://www.promptingguide.ai/",
        "type": "article"
      },
      {
        "title": "Ingeniería de Prompts vs Ajuste de Prompts: Una Explicación Detallada",
        "url": "https://medium.com/@aabhi02/prompt-engineering-vs-prompt-tuning-a-detailed-explanation-19ea8ce62ac4",
        "type": "article"
      }
    ]
  },
  "UIm54UmICKgep6s8Itcyv": {
    "title": "Embeddings y Búsqueda Vectorial",
    "description": "Los embeddings convierten palabras, imágenes u otros datos en listas de números llamados vectores. Cada vector conserva el significado del elemento original. Las cosas con significado similar obtienen vectores que se encuentran cerca en este espacio numérico. La búsqueda vectorial escanea un gran conjunto de vectores y encuentra los más cercanos a un vector de consulta, incluso si las palabras exactas difieren. Esto permite a los agentes de IA relacionar preguntas con respuestas, sugerir elementos relacionados y vincular ideas rápidamente.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Documentación de la API de Embeddings de OpenAI",
        "url": "https://platform.openai.com/docs/guides/embeddings/what-are-embeddings",
        "type": "article"
      },
      {
        "title": "Entendiendo los Embeddings y la Búsqueda Vectorial (Blog de Pinecone)",
        "url": "https://www.pinecone.io/learn/vector-embeddings/",
        "type": "article"
      }
    ]
  },
  "qwVQOwBTLA2yUgRISzC8k": {
    "title": "Comprender los Conceptos Básicos de RAG",
    "description": "RAG, abreviatura de Generación Aumentada por Recuperación, es una forma de hacer que los modelos de lenguaje den mejores respuestas permitiéndoles buscar información antes de responder. Primero, el sistema convierte la pregunta del usuario en una consulta de búsqueda y escanea una fuente de conocimiento, como un conjunto de documentos o una base de datos. Luego recupera los pasajes más relevantes, llamados “recuperaciones”. A continuación, el modelo de lenguaje lee esos pasajes y los usa, además de su propio conocimiento entrenado, para escribir la respuesta final. Esta mezcla de búsqueda y generación ayuda al modelo a mantenerse actualizado, reducir las conjeturas y citar hechos reales. Debido a que agrega información externa bajo demanda, RAG a menudo necesita menos ajuste fino y puede manejar temas que el modelo base nunca vio durante el entrenamiento.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué es RAG en IA y Cómo Usarlo?",
        "url": "https://www.v7labs.com/blog/what-is-rag",
        "type": "article"
      },
      {
        "title": "Una Introducción a RAG y RAG Simple y Complejo",
        "url": "https://medium.com/enterprise-rag/an-introduction-to-rag-and-simple-complex-rag-9c3aa9bd017b",
        "type": "article"
      },
      {
        "title": "Aprende RAG Desde Cero",
        "url": "https://www.youtube.com/watch?v=sVcwVQRHIc8",
        "type": "video"
      }
    ]
  },
  "B8dzg61TGaknuruBgkEJd": {
    "title": "Precios de Modelos Comunes",
    "description": "Cuando usas un modelo de lenguaje grande, generalmente pagas por la cantidad de texto que lee y escribe, contado en “tokens”. Un token equivale aproximadamente a cuatro caracteres o tres cuartas partes de una palabra. Los proveedores listan un precio por cada 1,000 tokens. Por ejemplo, GPT-3.5 Turbo puede costar alrededor de $0.002 por 1,000 tokens, mientras que GPT-4 es mucho más caro, como de $0.03 a $0.06 para prompts y de $0.06 a $0.12 para respuestas. Los modelos de código abierto más pequeños como Llama-2 pueden ser gratuitos si los ejecutas en tu propia computadora, pero aún pagas por el hardware o el tiempo en la nube. Los modelos de visión o audio a menudo tienen tarifas adicionales porque usan más cómputo. Al planificar los costos, estima los tokens en cada llamada, multiplica por el precio y agrega cualquier cargo de alojamiento o almacenamiento.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Precios de OpenAI",
        "url": "https://openai.com/api/pricing/",
        "type": "article"
      },
      {
        "title": "Guía Ejecutiva Sobre Precios de Agentes de IA",
        "url": "https://www.forbes.com/councils/forbesbusinesscouncil/2025/01/28/executive-guide-to-ai-agent-pricing-winning-strategies-and-models-to-drive-growth/",
        "type": "article"
      },
      {
        "title": "Precios de IA: ¿Cuánto Cuesta la Inteligencia Artificial en 2025?",
        "url": "https://www.internetsearchinc.com/ai-pricing-how-much-does-artificial-intelligence-cost/",
        "type": "article"
      }
    ]
  },
  "aFZAm44nP5NefX_9TpT0A": {
    "title": "¿Qué son los Agentes de IA?",
    "description": "Un agente de IA es un programa de computadora o robot que puede percibir su entorno, pensar en lo que percibe y luego actuar para alcanzar un objetivo. Recopila datos a través de cámaras, micrófonos o entradas de software, decide qué significan los datos usando reglas o patrones aprendidos, y elige la mejor acción para acercarse a su objetivo. Después de actuar, comprueba los resultados y aprende de ellos, para poder hacerlo mejor la próxima vez. Los chatbots, los coches autónomos y los personajes de juegos son todos ejemplos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué son los Agentes de IA? - Agentes en Inteligencia Artificial Explicados",
        "url": "https://aws.amazon.com/what-is/ai-agents/",
        "type": "article"
      },
      {
        "title": "Agentes de IA Explicados en Términos Sencillos para Principiantes",
        "url": "https://www.geeky-gadgets.com/ai-agents-explained-for-beginners/",
        "type": "article"
      },
      {
        "title": "¿Qué son los Agentes de IA?",
        "url": "https://www.youtube.com/watch?v=F8NKVhkZZWI",
        "type": "video"
      }
    ]
  },
  "2zsOUWJQ8e7wnoHmq1icG": {
    "title": "¿Qué son las Herramientas?",
    "description": "Las herramientas son habilidades o recursos adicionales a los que un agente de IA puede recurrir para completar un trabajo. Una herramienta puede ser cualquier cosa, desde una API de búsqueda web hasta una calculadora, una base de datos o un motor de traducción de idiomas. El agente envía una solicitud a la herramienta, obtiene el resultado y luego usa ese resultado para avanzar. Las herramientas permiten que un modelo central pequeño maneje tareas que serían difíciles o lentas por sí solo. También ayudan a mantener las respuestas actualizadas, precisas y basadas en datos reales. Elegir la herramienta adecuada y saber cuándo usarla son partes clave de la construcción de un agente inteligente.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Compara más de 50 Herramientas de Agentes de IA en 2025 - AIMultiple",
        "url": "https://research.aimultiple.com/ai-agent-tools/",
        "type": "article"
      },
      {
        "title": "Agentes de IA Explicados en Términos Sencillos para Principiantes",
        "url": "https://www.geeky-gadgets.com/ai-agents-explained-for-beginners/",
        "type": "article"
      }
    ]
  },
  "Eih4eybuYB3C2So8K0AT3": {
    "title": "Bucle del Agente",
    "description": "Un bucle de agente es el ciclo que permite a un agente de IA seguir trabajando hacia un objetivo. Primero, el agente recopila datos frescos de sus herramientas, sensores o memoria. A continuación, actualiza su estado interno y decide qué hacer, a menudo ejecutando un paso de planificación o razonamiento. Luego lleva a cabo la acción elegida, como llamar a una API, escribir en un archivo o enviar un mensaje. Después de actuar, comprueba el resultado y almacena nueva información. El bucle comienza de nuevo con los datos más recientes, para que el agente pueda ajustarse a los cambios y mejorar con el tiempo. Esta rápida repetición de observar–decidir–actuar le da al agente su poder.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué es un Bucle de Agente?",
        "url": "https://huggingface.co/learn/agents-course/en/unit1/agent-steps-and-structure",
        "type": "article"
      },
      {
        "title": "Construyamos tu Propio Bucle Agéntico",
        "url": "https://www.reddit.com/r/AI_Agents/comments/1js1xjz/lets_build_our_own_agentic_loop_running_in_our/",
        "type": "article"
      }
    ]
  },
  "LU76AhCYDjxdBhpMQ4eMU": {
    "title": "Percepción / Entrada del Usuario",
    "description": "La percepción, también llamada entrada del usuario, es el primer paso en un bucle de agente. El agente escucha y recopila datos del mundo exterior. Estos datos pueden ser texto escrito por un usuario, palabras habladas, imágenes de cámara, lecturas de sensores o contenido web obtenido a través de una API. El objetivo es convertir las señales crudas en una forma clara y utilizable. El agente puede limpiar el texto, traducir voz a texto, redimensionar una imagen o eliminar ruido de los valores de los sensores. Una buena percepción significa que el agente comienza su bucle con hechos, no con suposiciones. Si la entrada es incorrecta o poco clara, los pasos posteriores también fallarán. Por lo tanto, el manejo cuidadoso de la percepción mantiene todo el bucle del agente en marcha.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Percepción en IA: Comprendiendo sus Tipos e Importancia",
        "url": "https://marktalks.com/perception-in-ai-understanding-its-types-and-importance/",
        "type": "article"
      },
      {
        "title": "¿Qué es la Percepción del Agente de IA? - IBM",
        "url": "https://www.ibm.com/think/topics/ai-agent-perception",
        "type": "article"
      }
    ]
  },
  "ycPRgRYR4lEBQr_xxHKnM": {
    "title": "Razonar y Planificar",
    "description": "Razonar y Planificar es el momento en que un agente de IA piensa antes de actuar. El agente comienza con un objetivo y los hechos que ya conoce. Observa estos hechos y pregunta: “¿Qué necesito hacer a continuación para alcanzar el objetivo?” Divide el objetivo en pasos más pequeños, comprueba si cada paso tiene sentido y los ordena en un camino claro. El agente también puede adivinar qué podría salir mal y preparar pasos de respaldo. Una vez que el plan se siente sólido, el agente está listo para avanzar y tomar la primera acción.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "ReAct: Sinergizando Razonamiento y Actuación en Modelos de Lenguaje",
        "url": "https://react-lm.github.io/",
        "type": "article"
      },
      {
        "title": "Sistemas ReAct: Mejorando LLMs con Razonamiento y Acción",
        "url": "https://learnprompting.org/docs/agents/react",
        "type": "article"
      }
    ]
  },
  "sHYd4KsKlmw5Im3nQ19W8": {
    "title": "Actuación / Invocación de Herramientas",
    "description": "La actuación, también llamada invocación de herramientas, es el paso donde la IA elige una herramienta y la ejecuta para obtener datos del mundo real o para cambiar algo. El agente observa su objetivo actual y el plan que acaba de hacer. Luego elige la mejor herramienta, como una búsqueda web, una consulta de base de datos o una calculadora. El agente completa las entradas necesarias y envía la llamada. El sistema externo realiza el trabajo pesado y devuelve un resultado. La actuación termina cuando el agente almacena ese resultado para poder pensar en el siguiente movimiento.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué son las Herramientas en los Agentes de IA?",
        "url": "https://huggingface.co/learn/agents-course/en/unit1/tools",
        "type": "article"
      },
      {
        "title": "¿Qué es la Invocación de Herramientas en los Agentes?",
        "url": "https://www.useparagon.com/blog/ai-building-blocks-what-is-tool-calling-a-guide-for-pms",
        "type": "article"
      }
    ]
  },
  "ZJTrun3jK3zBGOTm1jdMI": {
    "title": "Observación y Reflexión",
    "description": "La observación y la reflexión forman la pausa de pensamiento en el bucle de un agente de IA. Primero, el agente observa el mundo que lo rodea, recopila datos frescos y ve qué ha cambiado. Luego hace una pausa para preguntar: “¿Qué significa esta nueva información para mi objetivo?” Durante esta breve verificación, el agente actualiza su memoria, detecta errores y clasifica lo que más importa. Estos pasos guían planes y acciones más sabios en el próximo ciclo. Sin una observación y reflexión cuidadosas, el agente dependería de hechos antiguos o incorrectos y pronto se desviaría del rumbo.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Mejores Prácticas para la Creación de Prompts y la Autoverificación",
        "url": "https://platform.openai.com/docs/guides/prompt-engineering",
        "type": "article"
      },
      {
        "title": "IA Autorreflexiva: Construyendo Agentes que Aprenden Observándose a Sí Mismos",
        "url": "https://arxiv.org/abs/2302.14045",
        "type": "article"
      }
    ]
  },
  "PPdAutqJF5G60Eg9lYBND": {
    "title": "Asistente personal",
    "description": "Un agente de IA de asistente personal es un programa inteligente que ayuda a una persona a gestionar las tareas diarias. Puede consultar un calendario, establecer recordatorios y enviar alertas para que nunca te pierdas una reunión. Puede leer correos electrónicos, resaltar puntos clave e incluso redactar respuestas rápidas. Si haces una pregunta, busca en fuentes confiables y da una respuesta corta. Puede pedir comida, reservar viajes o comprar en línea cuando das comandos simples de voz o texto. Como aprende tus hábitos, sugiere el mejor momento para trabajar, descansar o viajar. Todas estas acciones se ejecutan en segundo plano, ahorrándote tiempo y reduciendo el estrés.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Una Guía Completa sobre Asistentes Personales Impulsados por IA",
        "url": "https://medium.com/@alexander_clifford/a-complete-guide-on-ai-powered-personal-assistants-with-examples-2f5cd894d566",
        "type": "article"
      },
      {
        "title": "Los 9 Mejores Asistentes Personales de IA para el Trabajo, Chat y Hogar",
        "url": "https://saner.ai/best-ai-personal-assistants/",
        "type": "article"
      }
    ]
  },
  "PK8w31GlvtmAuU92sHaqr": {
    "title": "Generación de código",
    "description": "Los agentes de generación de código toman una solicitud en lenguaje sencillo, comprenden el objetivo y luego escriben o editan el código fuente para cumplirlo. Pueden crear pequeñas aplicaciones, agregar funciones, corregir errores, refactorizar código antiguo, escribir pruebas o traducir código de un idioma a otro. Esto ahorra tiempo a los desarrolladores, ayuda a los principiantes a aprender y reduce el error humano. Los equipos usan estos agentes dentro de editores de código, herramientas de chat y canalizaciones automatizadas. Al encargarse de tareas de codificación rutinarias, los agentes liberan a las personas para que se concentren en el diseño, la lógica y las necesidades del usuario.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Generación de Código Basada en Múltiples Agentes",
        "url": "https://arxiv.org/abs/2312.13010",
        "type": "article"
      },
      {
        "title": "Del Prompt a la Producción: Blog de Github",
        "url": "https://github.blog/ai-and-ml/github-copilot/from-prompt-to-production-building-a-landing-page-with-copilot-agent-mode/",
        "type": "article"
      },
      {
        "title": "Github Copilot",
        "url": "https://github.com/features/copilot",
        "type": "article"
      }
    ]
  },
  "wKYEaPWNsR30TIpHaxSsq": {
    "title": "Análisis de datos",
    "description": "Los agentes de IA pueden automatizar el análisis de datos extrayendo información de archivos, bases de datos o transmisiones en vivo. Limpian los datos detectando valores faltantes, valores atípicos y realizando correcciones inteligentes. Después de la limpieza, los agentes encuentran patrones como picos de ventas o caídas de sensores y pueden crear gráficos o paneles. Algunos ejecutan estadísticas básicas, otros aplican aprendizaje automático para predecir tendencias. Los agentes también pueden enviar alertas si los números superan los límites establecidos, ayudando a las personas a mantenerse informadas sin un monitoreo constante.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Cómo la IA Transformará el Análisis de Datos en 2025",
        "url": "https://www.devfi.com/ai-transform-data-analysis-2025/",
        "type": "article"
      },
      {
        "title": "Cómo la IA ha Cambiado el Mundo de la Analítica y la Ciencia de Datos",
        "url": "https://www.forbes.com/councils/forbestechcouncil/2025/01/28/how-ai-has-changed-the-world-of-analytics-and-data-science/k",
        "type": "article"
      }
    ]
  },
  "5oLc-235bvKhApxzYFkEc": {
    "title": "Web Scraping / Crawling",
    "description": "El web scraping y el crawling permiten a un agente de IA recopilar datos de muchas páginas web sin ayuda humana. El agente envía una solicitud a una página, lee el HTML y extrae las partes que solicitas, como precios, titulares de noticias o detalles de productos. Luego puede seguir los enlaces de la página para llegar a más páginas y repetir los mismos pasos. Este bucle crea un conjunto de datos grande y actualizado en minutos u horas en lugar de días. Las empresas lo utilizan para rastrear los precios del mercado, los investigadores para recopilar hechos o tendencias, y los desarrolladores para alimentar con datos frescos otros modelos de IA. Un buen código de scraping también respeta las reglas del sitio como robots.txt y evita saturar los servidores demasiado rápido, por lo que funciona sin problemas y de manera justa.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Crawl AI - Construye tu IA con un Prompt",
        "url": "https://www.crawlai.org/",
        "type": "article"
      },
      {
        "title": "Web Scraper Impulsado por IA con Crawl4AI y DeepSeek",
        "url": "https://brightdata.com/blog/web-data/crawl4ai-and-deepseek-web-scraping",
        "type": "article"
      },
      {
        "title": "Las Mejores Herramientas de Web Scraping para Aplicaciones de IA",
        "url": "https://www.thetoolnerd.com/p/best-web-scraping-tools-for-ai-applications",
        "type": "article"
      },
      {
        "title": "Las 8 Mejores Herramientas de Web Scraping con IA que Probé - Blog de HubSpot",
        "url": "https://blog.hubspot.com/website/ai-web-scraping",
        "type": "article"
      }
    ]
  },
  "ok8vN7VtCgyef5x6aoQaL": {
    "title": "NPC / IA de Juegos",
    "description": "Los estudios de juegos utilizan agentes de IA para controlar personajes no jugadores (NPC). El agente observa el estado del juego y decide acciones como moverse, hablar o luchar. Puede cambiar de táctica cuando el jugador cambia de estrategia, manteniendo las batallas frescas en lugar de predecibles. Un dador de misiones podría usar un agente para ofrecer pistas que se ajusten al progreso del jugador. En los juegos de mundo abierto, los agentes guían a las multitudes para moverse alrededor de obstáculos, establecer nuevos objetivos y reaccionar a las amenazas, haciendo que las ciudades se sientan vivas. Los diseñadores ahorran tiempo escribiendo reglas generales y dejando que los agentes completen los detalles en lugar de codificar manualmente cada escena. Un comportamiento de NPC más inteligente mantiene a los jugadores comprometidos y aumenta el valor de rejugabilidad.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Unity – IA para NPCs",
        "url": "https://dev.epicgames.com/documentation/en-us/unreal-engine/artificial-intelligence-in-unreal-engine?application_version=5.3",
        "type": "article"
      },
      {
        "title": "NPCs Impulsados por IA: El Futuro de los Videojuegos Explicado",
        "url": "https://www.capermint.com/blog/everything-you-need-to-know-about-non-player-character-npc/",
        "type": "article"
      }
    ]
  },
  "Bn_BkthrVX_vOuwQzvPZa": {
    "title": "Longitud Máxima",
    "description": "La Longitud Máxima establece el número máximo de tokens que un modelo de lenguaje puede generar en una respuesta. Los tokens son piezas de texto; aproximadamente 100 tokens equivalen a un párrafo corto. Un límite pequeño ahorra tiempo y costos, pero corre el riesgo de truncar las respuestas. Un límite grande permite respuestas completas y detalladas, pero necesita más cómputo y puede perder el enfoque. Elige los límites según la tarea: límites cortos para tuits, más largos para artículos. Ajustar cuidadosamente la Longitud Máxima ayuda a equilibrar la claridad, la velocidad y el costo.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Uso de Tokens de OpenAI",
        "url": "https://platform.openai.com/docs/guides/gpt/managing-tokens",
        "type": "article"
      },
      {
        "title": "Límites de Tamaño y Tokens Máximos",
        "url": "https://docs.anthropic.com/claude/docs/size-and-token-limits",
        "type": "article"
      },
      {
        "title": "Utilizando la Ventana de Contexto de Tokens Máximos de Anthropic Claude",
        "url": "https://medium.com/@nampreetsingh/utilising-max-token-context-window-of-anthropic-claude-on-amazon-bedrock-7377d94b2dfa",
        "type": "article"
      },
      {
        "title": "Controlando la Longitud de las Respuestas del Modelo OpenAI",
        "url": "https://help.openai.com/en/articles/5072518-controlling-the-length-of-openai-model-responses",
        "type": "article"
      },
      {
        "title": "Longitud Máxima del Modelo en IA",
        "url": "https://www.restack.io/p/ai-model-answer-max-model-length-cat-ai",
        "type": "article"
      },
      {
        "title": "Entendiendo los Tokens de ChatGPT/OpenAI",
        "url": "https://youtu.be/Mo3NV5n1yZk",
        "type": "video"
      }
    ]
  },
  "Y8EqzFx3qxtrSh7bWbbV8": {
    "title": "¿Qué es la Ingeniería de Prompts?",
    "description": "La ingeniería de prompts es la habilidad de escribir preguntas o instrucciones claras para que un sistema de IA dé la respuesta que deseas. Significa elegir las palabras correctas, agregar suficientes detalles y dar ejemplos cuando sea necesario. Un buen prompt le dice a la IA qué rol desempeñar, qué estilo usar y qué hechos incluir o evitar. Al probar y refinar el prompt, puedes mejorar la calidad, precisión y utilidad de la respuesta de la IA. En resumen, la ingeniería de prompts es guiar a la IA con texto bien diseñado para que pueda ayudarte mejor.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Visita el Roadmap Dedicado de Ingeniería de Prompts",
        "url": "https://roadmap.sh/prompt-engineering",
        "type": "article"
      },
      {
        "title": "¿Qué es la Ingeniería de Prompts? - Ingeniería de Prompts de IA Explicada - AWS",
        "url": "https://aws.amazon.com/what-is/prompt-engineering/",
        "type": "article"
      },
      {
        "title": "¿Qué es la Ingeniería de Prompts? Una Guía Detallada para 2025",
        "url": "https://www.datacamp.com/blog/what-is-prompt-engineering-the-future-of-ai-communication",
        "type": "article"
      }
    ]
  },
  "qFKFM2qNPEN7EoD0V-1SM": {
    "title": "Sé específico en lo que quieres",
    "description": "Cuando le pides a una IA que haga algo, las palabras claras y exactas la ayudan a dar la respuesta que deseas. Indica el objetivo, el formato y cualquier límite desde el principio. Di para quién es la respuesta, cuán larga debe ser y qué omitir. Si los números, fechas o fuentes importan, menciónalos. Por ejemplo, en lugar de “Explica la Segunda Guerra Mundial”, prueba “Enumera tres eventos clave de la Segunda Guerra Mundial con fechas y un hecho breve para cada uno”. Ser así de preciso reduce las conjeturas, evita detalles adicionales no deseados y ahorra tiempo al reducir las preguntas de seguimiento.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Guía de Ingeniería de Prompts",
        "url": "https://www.promptingguide.ai/",
        "type": "article"
      },
      {
        "title": "Ejemplos de Prompts de IA, Plantillas y Consejos para Educadores",
        "url": "https://honorlock.com/blog/education-ai-prompt-writing/",
        "type": "article"
      },
      {
        "title": "Cómo Pedirle Cualquier Cosa a la IA: El Arte de Crear Prompts",
        "url": "https://sixtyandme.com/using-ai-prompts/",
        "type": "article"
      }
    ]
  },
  "6I42CoeWX-kkFXTKAY7rw": {
    "title": "Proporciona contexto adicional",
    "description": "Proporcionar contexto adicional significa darle a la IA suficientes hechos de fondo, restricciones y objetivos para que pueda responder de la manera que necesitas. Comienza nombrando el tema y el propósito de la respuesta. Agrega para quién es la respuesta, el tono que deseas y cualquier límite como longitud, formato o estilo. Enumera hechos clave, datos o ejemplos que sean importantes para la tarea. Este detalle adicional evita que el modelo adivine y mantiene las respuestas enfocadas. Piénsalo como guiar a un nuevo compañero de equipo: comparte los detalles que necesitan, pero mantenlos cortos y claros.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué es el Contexto en la Ingeniería de Prompts?",
        "url": "https://www.godofprompt.ai/blog/what-is-context-in-prompt-engineering",
        "type": "article"
      },
      {
        "title": "La Importancia del Contexto para Sistemas de IA Confiables",
        "url": "https://medium.com/mathco-ai/the-importance-of-context-for-reliable-ai-systems-and-how-to-provide-context-009bd1ac7189/",
        "type": "article"
      },
      {
        "title": "Ingeniería de Contexto: Por Qué es Importante Alimentar a la IA con el Contexto Correcto",
        "url": "https://inspirednonsense.com/context-engineering-why-feeding-ai-the-right-context-matters-353e8f87d6d3",
        "type": "article"
      }
    ]
  },
  "sUwdtOX550tSdceaeFPmF": {
    "title": "Usa términos técnicos relevantes",
    "description": "Cuando una tarea involucra un campo especial como derecho, medicina o informática, incluye las palabras correctas del dominio en tu prompt para que la IA sepa exactamente a qué te refieres. Pide “algoritmos de ordenación O(n log n)” en lugar de solo “ordenaciones rápidas”, o “código de estado HTTP 404” en lugar de “error de página no encontrada”. El término correcto acota el tema, elimina las conjeturas y dirige el modelo hacia la base de conocimientos que necesitas. También mantiene la respuesta en el nivel adecuado, porque el modelo ve que entiendes el campo y responderá con la profundidad correspondiente. Revisa la ortografía y el uso de mayúsculas y minúsculas; “SQL” y “sql” se consideran iguales, pero “Sequel” no. No sobrecargues el prompt con palabras de moda, agrega solo las palabras que realmente importan. El objetivo es un lenguaje claro más las etiquetas técnicas exactas que utiliza el tema.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Glosario de Términos de IA: Términos de IA que Debes Conocer en 2024",
        "url": "https://www.moveworks.com/us/en/resources/ai-terms-glossary",
        "type": "article"
      },
      {
        "title": "15 Términos Esenciales sobre Agentes de IA que Debes Conocer",
        "url": "https://shivammore.medium.com/15-essential-ai-agent-terms-you-must-know-6bfc2f332f6d",
        "type": "article"
      },
      {
        "title": "Ejemplos y Casos de Uso de Agentes de IA: Aplicaciones Reales en 2025",
        "url": "https://eastgate-software.com/ai-agent-examples-use-cases-real-applications-in-2025/",
        "type": "article"
      }
    ]
  },
  "yulzE4ZNLhXOgHhG7BtZQ": {
    "title": "Usa Ejemplos en tu Prompt",
    "description": "Una forma clara de guiar a una IA es colocar una o dos muestras cortas dentro de tu prompt. Muestra una entrada pequeña y la salida exacta que esperas. La IA estudia estos pares y copia su patrón. Usa palabras sencillas en la muestra, mantén el formato estable y etiqueta cada parte para que el modelo sepa cuál es cuál. Si necesitas una lista, muestra una lista; si necesitas una tabla, incluye una tabla pequeña. Los buenos ejemplos reducen las conjeturas, disminuyen los errores y te ahorran escribir reglas largas.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "10 Ejemplos de Agentes de IA del Mundo Real en 2025",
        "url": "https://www.chatbase.co/blog/ai-agent-examples",
        "type": "article"
      },
      {
        "title": "Guía de Creación de Prompts para GPT-4.1",
        "url": "https://cookbook.openai.com/examples/gpt4-1_prompting_guide",
        "type": "article"
      },
      {
        "title": "Ejemplos y Casos de Uso de Agentes de IA: Aplicaciones Reales en 2025",
        "url": "https://eastgate-software.com/ai-agent-examples-use-cases-real-applications-in-2025/",
        "type": "article"
      }
    ]
  },
  "noTuUFnHSBzn7GKG9UZEi": {
    "title": "Itera y Prueba tus Prompts",
    "description": "Después de escribir un primer prompt, trátalo como un borrador, no como la versión final. Ejecútalo con la IA, revisa el resultado y anota lo que falta, está mal o es confuso. Cambia una cosa a la vez, como agregar un ejemplo, un límite de longitud o una solicitud de tono. Prueba de nuevo y ve si el resultado se acerca más a lo que deseas. Mantén un registro de cada cambio y su efecto, para que puedas aprender patrones que funcionan. Detente cuando el resultado sea claro, correcto y repetible. Este bucle de probar, observar, ajustar y reintentar convierte un prompt preliminar en uno sólido.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Mejores Prácticas de Ingeniería de Prompts",
        "url": "https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/",
        "type": "course"
      },
      {
        "title": "Domina la Creación Iterativa de Prompts: Una Guía",
        "url": "https://blogs.vreamer.space/master-iterative-prompting-a-guide-to-more-effective-interactions-with-ai-50a736eaec38",
        "type": "article"
      },
      {
        "title": "Ingeniería de Prompts: El Proceso Iterativo",
        "url": "https://www.youtube.com/watch?v=dOxUroR57xs",
        "type": "video"
      }
    ]
  },
  "wwHHlEoPAx0TLxbtY6nMA": {
    "title": "Especifica Longitud, formato, etc.",
    "description": "Cuando le das una tarea a una IA, deja en claro cuán larga debe ser la respuesta y qué forma debe tomar. Di “Escribe 120 palabras” o “Da los pasos como una lista numerada”. Si necesitas una tabla, indica los nombres de las columnas y el orden. Si quieres viñetas, menciónalo. Decirle a la IA que use texto sin formato, JSON o markdown evita las conjeturas y ahorra tiempo. Límites claros de longitud mantienen la respuesta enfocada. Un formato fijo facilita que las personas u otro software lean y usen el resultado. Siempre coloca estas reglas cerca del inicio de tu prompt para que la IA las vea como importantes.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Dominando la Ingeniería de Prompts: Formato, Longitud y Audiencia",
        "url": "https://techlasi.com/savvy/mastering-prompt-engineering-format-length-and-audience-examples-for-2024/",
        "type": "article"
      },
      {
        "title": "Guía Definitiva de Ingeniería de Prompts",
        "url": "https://promptdrive.ai/prompt-engineering/",
        "type": "article"
      }
    ]
  },
  "qakbxB8xe7Y8gejC5cZnK": {
    "title": "Definición de Herramienta",
    "description": "Una herramienta es cualquier habilidad o función a la que un agente de IA puede recurrir para realizar un trabajo. Puede ser tan simple como una calculadora para matemáticas o tan compleja como una API que obtiene datos meteorológicos en vivo. Cada herramienta tiene un nombre, una breve descripción de lo que hace y una lista clara de las entradas que necesita y las salidas que devuelve. El planificador del agente lee esta definición para decidir cuándo usar la herramienta. Las buenas definiciones de herramientas son precisas y no dejan lugar a dudas, para que el agente no adivine ni las use incorrectamente. También establecen límites, como cuántas veces se puede llamar a una herramienta o cuántos datos se pueden extraer, lo que ayuda a controlar costos y errores. Piensa en una definición de herramienta como una tarjeta de receta que el agente sigue cada vez que necesita esa habilidad.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Comprendiendo la Función del Agente en IA: Roles y Responsabilidades Clave",
        "url": "https://pingax.com/ai/agent/function/understanding-the-agent-function-in-ai-key-roles-and-responsibilities/",
        "type": "article"
      },
      {
        "title": "¿Qué es una Herramienta de IA?",
        "url": "https://www.synthesia.io/glossary/ai-tool",
        "type": "article"
      }
    ]
  },
  "kBtqT8AduLoYDWopj-V9_": {
    "title": "Búsqueda Web",
    "description": "La búsqueda web permite a un agente de IA extraer hechos frescos, noticias y ejemplos de Internet mientras está trabajando. El agente convierte una solicitud del usuario en palabras de búsqueda, las envía a un motor de búsqueda y lee la lista de resultados. Luego sigue los enlaces más prometedores, toma el texto de la página y selecciona las partes que responden a la tarea. Esto ayuda al agente a manejar temas que no estaban en sus datos de entrenamiento, actualizar conocimientos antiguos o verificar detalles. La búsqueda web cubre casi cualquier tema y es mucho más rápida que la investigación manual, pero el agente debe estar atento a anuncios, sesgos o páginas incorrectas y verificar las fuentes para mantenerse preciso.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Los 8 Mejores Motores de Búsqueda con IA para 2025",
        "url": "https://usefulai.com/tools/ai-search-engines",
        "type": "article"
      },
      {
        "title": "Agente de Búsqueda Web - Documentación de PraisonAI",
        "url": "https://docs.praison.ai/agents/websearch",
        "type": "article"
      }
    ]
  },
  "mS0EVCkWuPN_GkVPng4A2": {
    "title": "Ejecución de Código / REPL",
    "description": "La Ejecución de Código o REPL (Bucle de Lectura-Evaluación-Impresión) permite a un agente de IA ejecutar pequeños fragmentos de código bajo demanda, ver el resultado de inmediato y usar ese resultado para decidir qué hacer a continuación. El agente “lee” el código, lo “evalúa” en un sandbox seguro, “imprime” la salida y luego vuelve al bucle para más entrada. Con esta herramienta, el agente puede probar ideas, realizar cálculos matemáticos, transformar texto, llamar a API o inspeccionar datos sin esperar una compilación o implementación completa. Python, JavaScript o incluso comandos de shell son opciones comunes porque se inician rápidamente y tienen muchas bibliotecas. La retroalimentación rápida ayuda al agente a detectar errores temprano y refinar su plan paso a paso. El sandboxing mantiene seguro el sistema anfitrión al bloquear acciones peligrosas como eliminar archivos o realizar llamadas de red prohibidas. En general, una herramienta de Ejecución de Código / REPL le da al agente un banco de trabajo rápido y flexible para la resolución de problemas.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué es un REPL?",
        "url": "https://docs.replit.com/getting-started/intro-replit",
        "type": "article"
      },
      {
        "title": "Agente de IA para Ejecución de Código",
        "url": "https://docs.praison.ai/features/codeagent",
        "type": "article"
      },
      {
        "title": "Construyendo un Entorno de Ejecución de Código para Agentes de IA",
        "url": "https://murraycole.com/posts/ai-code-execution-environment",
        "type": "article"
      },
      {
        "title": "Herramienta de Código Python",
        "url": "https://python.langchain.com/docs/integrations/tools/python/",
        "type": "article"
      }
    ]
  },
  "sV1BnA2-qBnXoKpUn-8Ub": {
    "title": "Consultas a Bases de Datos",
    "description": "Las consultas a bases de datos permiten a un agente de IA obtener, agregar, cambiar o eliminar datos almacenados en una base de datos. El agente envía una solicitud escrita en un lenguaje de consulta, más comúnmente SQL. El motor de la base de datos luego busca en sus tablas y devuelve solo las filas y columnas que coinciden con las reglas de la solicitud. Con esta herramienta, el agente puede responder preguntas que necesitan números actualizados, registros de usuarios u otros hechos almacenados. También puede escribir nuevas entradas o ajustar las antiguas para mantener los datos actualizados. Debido a que las consultas funcionan en tiempo real y siguen reglas claras, le dan al agente una forma confiable de manejar grandes conjuntos de información estructurada.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Construyendo tu Propio Agente de Base de Datos",
        "url": "https://www.deeplearning.ai/short-courses/building-your-own-database-agent/",
        "type": "article"
      }
    ]
  },
  "52qxjZILV-X1isup6dazC": {
    "title": "Solicitudes de API",
    "description": "Las solicitudes de API permiten a un agente de IA pedir datos o una acción a otro servicio. El agente construye un mensaje corto que sigue las reglas del servicio, lo envía por Internet y espera una respuesta. Por ejemplo, puede llamar a una API meteorológica para obtener el pronóstico de hoy o a una API de pagos para cobrar a un cliente. Cada solicitud tiene un método como GET o POST, una URL y, a menudo, un pequeño bloque de JSON con los detalles necesarios. El servicio responde con otro bloque JSON que el agente lee y utiliza. Debido a que las solicitudes de API son rápidas y claras, son una herramienta común para conectar el agente a muchos otros sistemas sin trabajo adicional.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Introducción a las APIs - MDN Web Docs",
        "url": "https://developer.mozilla.org/en-US/docs/Web/API/Introduction_to_APIs",
        "type": "article"
      },
      {
        "title": "Cómo las APIs Impulsan a los Agentes de IA: Una Guía Completa",
        "url": "https://blog.treblle.com/api-guide-for-ai-agents/",
        "type": "article"
      }
    ]
  },
  "qaNr5I-NQPnfrRH7ynGTl": {
    "title": "Correo Electrónico / Slack / SMS",
    "description": "El correo electrónico, Slack y SMS son canales de mensajes que un agente de IA puede usar para actuar en tareas y compartir actualizaciones. El agente escribe y envía correos electrónicos para dar informes detallados o recopilar archivos. Publica en Slack para chatear con un equipo, responder preguntas o activar alertas dentro de un espacio de trabajo. Envía mensajes de texto SMS para avisos rápidos como recordatorios, confirmaciones o advertencias cuando se necesita una respuesta rápida. Al elegir el canal correcto, el agente llega a los usuarios donde ya se comunican, se asegura de que la información importante llegue a tiempo e incluso puede recopilar respuestas para mantener una tarea en movimiento.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "API de Mensajería de Twilio",
        "url": "https://www.twilio.com/docs/usage/api",
        "type": "article"
      },
      {
        "title": "Agentes de IA de Slack",
        "url": "https://slack.com/ai-agents",
        "type": "article"
      }
    ]
  },
  "BoJqZvdGam4cd6G6yK2IV": {
    "title": "Acceso al Sistema de Archivos",
    "description": "El acceso al sistema de archivos permite a un agente de IA leer, crear, cambiar o eliminar archivos y carpetas en una computadora o servidor. Con este poder, el agente puede abrir un archivo de texto para extraer datos, escribir un nuevo informe, guardar registros o limpiar archivos antiguos sin ayuda humana. También puede mover archivos entre carpetas para mantener las cosas organizadas. Esta herramienta es útil para tareas como el procesamiento de datos, la generación de informes y los trabajos de respaldo. Se necesitan fuertes controles de seguridad para que el agente solo toque los archivos correctos, evite datos privados y no pueda dañar el sistema por error.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Servidor MCP de Sistema de Archivos para Agentes de IA",
        "url": "https://playbooks.com/mcp/mateicanavra-filesystem",
        "type": "article"
      },
      {
        "title": "API de Acceso al Sistema de Archivos",
        "url": "https://developer.mozilla.org/en-US/docs/Web/API/File_System_Access_API",
        "type": "article"
      },
      {
        "title": "Comprendiendo los Permisos de Archivos y la Seguridad",
        "url": "https://linuxize.com/post/understanding-linux-file-permissions/",
        "type": "article"
      },
      {
        "title": "¿Cómo Funcionan los Sistemas de Archivos?",
        "url": "https://www.youtube.com/watch?v=KN8YgJnShPM",
        "type": "video"
      }
    ]
  },
  "TBH_DZTAfR8Daoh-njNFC": {
    "title": "¿Qué es la Memoria del Agente?",
    "description": "La memoria del agente es la parte de un agente de IA que realiza un seguimiento de lo que ya ha sucedido. Almacena mensajes de usuarios anteriores, hechos que el agente ha aprendido y sus propios pasos previos. Esto ayuda al agente a recordar objetivos, gustos y disgustos del usuario, y detalles importantes a través de turnos o sesiones. La memoria puede ser a corto plazo, durando solo una conversación, oa largo plazo, durando muchas. Con una buena memoria, el agente evita repetir preguntas, se mantiene consistente y planifica mejores acciones. Sin ella, el agente olvidaría todo cada vez y se sentiría desenfocado.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Memoria Agéntica para Agentes LLM",
        "url": "https://arxiv.org/abs/2502.12110",
        "type": "article"
      },
      {
        "title": "Gestión de la Memoria en Agentes de IA",
        "url": "https://python.langchain.com/docs/how_to/chatbots_memory/",
        "type": "article"
      },
      {
        "title": "Almacenamiento y Recuperación de Conocimiento para Agentes",
        "url": "https://www.pinecone.io/learn/langchain-retrieval-augmentation/",
        "type": "article"
      },
      {
        "title": "Memoria a Corto Plazo vs Memoria a Largo Plazo en Agentes de IA",
        "url": "https://adasci.org/short-term-vs-long-term-memory-in-ai-agents/",
        "type": "article"
      },
      {
        "title": "Construyendo Memoria Similar al Cerebro para Agentes de IA",
        "url": "https://www.youtube.com/watch?v=VKPngyO0iKg",
        "type": "video"
      }
    ]
  },
  "M3U6RfIqaiut2nuOibY8W": {
    "title": "Memoria a Corto Plazo",
    "description": "La memoria a corto plazo son los hechos que se pasan como parte del prompt al LLM, por ejemplo, podría haber un prompt como el siguiente:\n\n    Perfil del Usuario:\n    - nombre: {nombre}\n    - edad: {edad}\n    - experiencia: {experiencia}\n    \n    El usuario está aprendiendo actualmente sobre {tema_actual}. El usuario tiene algunos objetivos en mente que son:\n    - {objetivo_1}\n    - {objetivo_2}\n    - {objetivo_3}\n    \n    Ayuda al usuario a alcanzar los objetivos.\n    \n\nObserva cómo inyectamos el perfil del usuario, el tema actual y los objetivos en el prompt. Todas estas son memorias a corto plazo.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Gestión de la Memoria en Agentes de IA",
        "url": "https://python.langchain.com/docs/how_to/chatbots_memory/",
        "type": "article"
      },
      {
        "title": "Construye Agentes de IA Más Inteligentes: Gestiona la Memoria a Corto y Largo Plazo",
        "url": "https://redis.io/blog/build-smarter-ai-agents-manage-short-term-and-long-term-memory-with-redis/",
        "type": "article"
      },
      {
        "title": "Almacenamiento y Recuperación de Conocimiento para Agentes",
        "url": "https://www.pinecone.io/learn/langchain-retrieval-augmentation/",
        "type": "article"
      },
      {
        "title": "Memoria a Corto Plazo vs Memoria a Largo Plazo en Agentes de IA",
        "url": "https://adasci.org/short-term-vs-long-term-memory-in-ai-agents/",
        "type": "article"
      },
      {
        "title": "Construyendo Memoria Similar al Cerebro para Agentes de IA",
        "url": "https://www.youtube.com/watch?v=VKPngyO0iKg",
        "type": "video"
      }
    ]
  },
  "Ue633fz6Xu2wa2-KOAtdP": {
    "title": "Memoria a Largo Plazo",
    "description": "La memoria a largo plazo en un agente de IA almacena información importante para uso futuro, como un cuaderno digital. Guarda hechos, eventos pasados, preferencias del usuario y habilidades aprendidas para que el agente pueda tomar decisiones más inteligentes y consistentes con el tiempo. A diferencia de la memoria a corto plazo, estos datos sobreviven a través de las sesiones. Cuando surge una situación similar, el agente puede mirar hacia atrás y usar lo que ya sabe. La memoria a largo plazo generalmente reside en una base de datos, sistema de archivos o almacén de vectores y puede contener texto, números, incrustaciones o estados de conversación pasados. Una buena gestión de la memoria a largo plazo es clave para construir agentes que se sientan personalizados y mejoren con la experiencia.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Memoria a Largo Plazo en Agentes de IA",
        "url": "https://medium.com/@alozie_igbokwe/ai-101-long-term-memory-in-ai-agents-35f87f2d0ce0",
        "type": "article"
      },
      {
        "title": "Gestión de la Memoria en Agentes de IA",
        "url": "https://python.langchain.com/docs/how_to/chatbots_memory/",
        "type": "article"
      },
      {
        "title": "Almacenamiento y Recuperación de Conocimiento para Agentes",
        "url": "https://www.pinecone.io/learn/langchain-retrieval-augmentation/",
        "type": "article"
      },
      {
        "title": "Memoria a Corto Plazo vs Memoria a Largo Plazo en Agentes de IA",
        "url": "https://adasci.org/short-term-vs-long-term-memory-in-ai-agents/",
        "type": "article"
      },
      {
        "title": "Construyendo Memoria Similar al Cerebro para Agentes de IA",
        "url": "https://www.youtube.com/watch?v=VKPngyO0iKg",
        "type": "video"
      }
    ]
  },
  "EfCCNqLMJpWKKtamUa5gK": {
    "title": "Memoria Episódica vs Semántica",
    "description": "La memoria del agente a menudo tiene dos partes. La memoria episódica es relevante para el contexto de la conversación actual y puede perderse después de que finaliza la conversación. La memoria semántica es relevante para el conocimiento más amplio del agente y es persistente.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué es la Memoria del Agente de IA? - IBM",
        "url": "https://www.ibm.com/think/topics/ai-agent-memory",
        "type": "article"
      },
      {
        "title": "Memoria Episódica vs. Memoria Semántica: Las Diferencias Clave",
        "url": "https://www.magneticmemorymethod.com/episodic-vs-semantic-memory/",
        "type": "article"
      },
      {
        "title": "Sistemas de Memoria en LangChain",
        "url": "https://python.langchain.com/docs/how_to/chatbots_memory/",
        "type": "article"
      }
    ]
  },
  "wkS4yOJ3JdZQE_yBID8K7": {
    "title": "RAG y Bases de Datos Vectoriales",
    "description": "RAG, abreviatura de Generación Aumentada por Recuperación, permite a un agente de IA extraer hechos de datos almacenados cada vez que responde. Los datos se encuentran en una base de datos vectorial. En esa base de datos, cada fragmento de texto se convierte en una lista de números llamada vector. Ideas similares crean vectores que se encuentran cerca, por lo que el agente puede encontrar fragmentos relacionados rápidamente. Cuando el usuario hace una pregunta, el agente convierte la pregunta en su propio vector, encuentra los fragmentos más cercanos y los lee. Luego escribe una respuesta que mezcla el nuevo prompt con esos fragmentos. Debido a que el almacén de datos puede contener muchos chats, documentos o notas anteriores, este proceso le da al agente una memoria funcional sin saturar todo en el prompt. Reduce el costo de los tokens, mantiene las respuestas en tema y permite que la memoria crezca con el tiempo.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Comprendiendo la Generación Aumentada por Recuperación (RAG) y las Bases de Datos Vectoriales",
        "url": "https://pureai.com/Articles/2025/03/03/Understanding-RAG.aspx",
        "type": "article"
      },
      {
        "title": "Construye Sistemas Avanzados de Generación Aumentada por Recuperación",
        "url": "https://learn.microsoft.com/en-us/azure/developer/ai/advanced-retrieval-augmented-generation",
        "type": "article"
      },
      {
        "title": "¿Qué es la Generación Aumentada por Recuperación, también conocida como RAG?",
        "url": "https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/",
        "type": "article"
      }
    ]
  },
  "QJqXHV8VHPTnfYfmKPzW7": {
    "title": "Almacenamiento de Perfiles de Usuario",
    "description": "El almacenamiento de perfiles de usuario es la parte de la memoria de un agente de IA que contiene hechos estables sobre cada usuario, como nombre, grupo de edad, idioma, elecciones pasadas y objetivos a largo plazo. El agente guarda estos datos en un archivo o pequeña base de datos para poder cargarlos cada vez que el mismo usuario regresa. Al mantener el perfil separado de los registros de conversación a corto plazo, el agente puede recordar las preferencias sin mezclarlas con el historial de chat temporal. El perfil se actualiza solo cuando el usuario declara una nueva preferencia duradera o cuando la información antigua cambia, lo que ayuda a prevenir la desviación o la hinchazón.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Tecnología de Almacenamiento Explicada: IA y Almacenamiento de Datos",
        "url": "https://www.computerweekly.com/feature/Storage-technology-explained-AI-and-the-data-storage-it-needs",
        "type": "article"
      },
      {
        "title": "La Guía del Arquitecto sobre Almacenamiento para IA - The New Stack",
        "url": "https://thenewstack.io/the-architects-guide-to-storage-for-ai/",
        "type": "article"
      }
    ]
  },
  "jTDC19BTWCqxqMizrIJHr": {
    "title": "Resumen / Compresión",
    "description": "El resumen o la compresión permiten a un agente de IA conservar la esencia de los chats pasados sin guardar cada línea. Después de una conversación, el agente ejecuta un pequeño modelo o conjunto de reglas que extrae hechos clave, objetivos y sentimientos y los escribe en una nota breve. Esta nota va a la memoria a largo plazo, mientras que el chat completo se puede descartar o almacenar en otro lugar. Debido a que la nota es corta, el agente gasta menos tokens cuando carga la memoria en el siguiente prompt, por lo que los costos se mantienen bajos y la velocidad alta. Los buenos resúmenes omiten bromas secundarias y relleno, pero conservan nombres, fechas, tareas abiertas y preferencias del usuario. El agente puede actualizar la nota después de cada sesión, sobrescribiendo puntos antiguos que ya no son ciertos. Este proceso permite que el agente recuerde lo que importa incluso después de cientos de turnos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Evaluación de LLMs para Resumen de Texto",
        "url": "https://insights.sei.cmu.edu/blog/evaluating-llms-for-text-summarization-introduction/",
        "type": "article"
      },
      {
        "title": "La Guía Definitiva para el Resumen de Documentos con IA",
        "url": "https://www.documentllm.com/blog/ai-document-summarization-guide",
        "type": "article"
      }
    ]
  },
  "m-97m7SI0XpBnhEE8-_1S": {
    "title": "Estrategias de Olvido / Envejecimiento",
    "description": "Las estrategias de olvido o envejecimiento ayudan a un agente de IA a conservar solo las partes útiles de su memoria y descartar el resto con el tiempo. El agente puede etiquetar cada recuerdo con una marca de tiempo y disminuir su importancia a medida que envejece, o puede eliminar elementos que no se han utilizado durante un tiempo, de forma muy parecida a una lista de “menos recientemente utilizados”. Algunos sistemas asignan a cada recuerdo una puntuación de relevancia; cuando el espacio se agota, borran primero los elementos con la puntuación más baja. Otros mantienen una ventana deslizante de longitud fija de los eventos más recientes o crean resúmenes cortos y los almacenan en lugar de detalles sin procesar. Estos métodos evitan que el almacén de memoria crezca sin límites, reducen los costos de almacenamiento y permiten que el agente se concentre en los objetivos actuales. Elegir la combinación correcta de reglas de envejecimiento es una compensación: olvidar demasiado rápido y el agente pierde contexto, olvidar demasiado lento y desperdicia recursos o reacciona a hechos obsoletos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Gestión de la Memoria",
        "url": "https://python.langchain.com/docs/how_to/chatbots_memory/",
        "type": "article"
      },
      {
        "title": "Gestión de la Memoria para Agentes de IA",
        "url": "https://techcommunity.microsoft.com/blog/azure-ai-services-blog/memory-management-for-ai-agents/4406359",
        "type": "article"
      }
    ]
  },
  "53xDks6JQ33fHMa3XcuCd": {
    "title": "ReAct (Razonar + Actuar)",
    "description": "ReAct es un patrón de agente que hace que un modelo alterne entre dos pasos simples: Razonar y Actuar. Primero, el agente escribe un pensamiento breve que resume lo que sabe y lo que debería intentar a continuación. Luego realiza una acción como llamar a una API, ejecutar código o buscar un documento. El resultado de esa acción se retroalimenta, lo que le da al agente nuevos hechos sobre los que pensar. Este bucle se repite hasta que se completa la tarea. Al mostrar sus pensamientos en texto sin formato, el agente puede ser inspeccionado, depurado e incluso corregido sobre la marcha. La clara división entre pensar y hacer también reduce los movimientos desperdiciados y guía al modelo hacia un progreso constante. ReAct funciona bien con modelos de lenguaje grandes porque pueden generar la cadena de pensamientos y elegir la siguiente herramienta en la misma respuesta.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "ReAct: Sinergizando Razonamiento y Actuación en Modelos de Lenguaje",
        "url": "https://react-lm.github.io/",
        "type": "article"
      },
      {
        "title": "Sistemas ReAct: Mejorando LLMs con Razonamiento y Acción",
        "url": "https://learnprompting.org/docs/agents/react",
        "type": "article"
      }
    ]
  },
  "1B0IqRNYdtbHDi1jHSXuI": {
    "title": "Protocolo de Contexto del Modelo (MCP)",
    "description": "El Protocolo de Contexto del Modelo (MCP) es un libro de reglas que le dice a un agente de IA cómo empaquetar la información de fondo antes de enviar un prompt a un modelo de lenguaje. Enumera qué piezas van en el prompt —cosas como el rol del sistema, la solicitud del usuario, la memoria pasada, las llamadas a herramientas o los fragmentos de código— y fija su orden. Etiquetas claras marcan cada pieza, para que tanto los humanos como las máquinas puedan ver dónde termina una parte y comienza la siguiente. Mantener el formato estable reduce la confusión, permite que diferentes herramientas trabajen juntas y facilita la prueba o el intercambio de modelos más tarde. Cuando los agentes siguen el MCP, el modelo recibe un prompt limpio y completo y puede dar mejores respuestas.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Protocolo de Contexto del Modelo",
        "url": "https://github.com/modelcontextprotocol/modelcontextprotocol",
        "type": "opensource"
      },
      {
        "title": "Protocolo de Contexto del Modelo",
        "url": "https://modelcontextprotocol.io/introduction",
        "type": "article"
      },
      {
        "title": "Presentamos el Servidor MCP de Azure",
        "url": "https://devblogs.microsoft.com/azure-sdk/introducing-the-azure-mcp-server/",
        "type": "article"
      },
      {
        "title": "La Guía Definitiva de MCP",
        "url": "https://guangzhengli.com/blog/en/model-context-protocol",
        "type": "article"
      }
    ]
  },
  "9FryAIrWRHh8YlzKX3et5": {
    "title": "Hosts MCP",
    "description": "Los Hosts MCP son computadoras o servicios que ejecutan el Protocolo de Contexto del Modelo. Manejan las llamadas entrantes, cargan el manifiesto MCP, verifican las solicitudes y pasan datos entre usuarios, herramientas y modelos de lenguaje. Los hosts pueden almacenar en caché mensajes recientes, rastrear el uso de tokens y agregar controles de seguridad o facturación antes de enviar prompts al modelo. Exponen un punto final de API para que las aplicaciones puedan conectarse fácilmente. Puedes ejecutar un host en tu computadora portátil para realizar pruebas o implementarlo en plataformas en la nube para escalar. El host actúa como el puente confiable donde se encuentran agentes, herramientas y datos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "punkeye/awesome-mcp-servers",
        "url": "https://github.com/punkpeye/awesome-mcp-servers",
        "type": "opensource"
      },
      {
        "title": "Alojamiento Sin Servidor de Vercel",
        "url": "https://vercel.com/docs",
        "type": "article"
      },
      {
        "title": "La Guía Definitiva de MCP",
        "url": "https://guangzhengli.com/blog/en/model-context-protocol",
        "type": "article"
      },
      {
        "title": "Servidores MCP de AWS para Asistentes de Código",
        "url": "https://aws.amazon.com/blogs/machine-learning/introducing-aws-mcp-servers-for-code-assistants-part-1/",
        "type": "article"
      }
    ]
  },
  "CGVstUxVXLJcYZrwk3iNQ": {
    "title": "Cliente MCP",
    "description": "El Cliente MCP es la parte de un agente de IA que habla con la API del modelo de lenguaje. Recopila mensajes, archivos y señales de herramientas, los empaqueta utilizando el Protocolo de Contexto del Modelo y los envía al modelo. Cuando llega una respuesta, la desempaqueta, comprueba el formato y pasa el resultado a otros módulos. También rastrea el uso de tokens, filtra datos privados, reintenta llamadas fallidas y registra eventos importantes para la depuración.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Protocolo de Contexto del Modelo",
        "url": "https://github.com/modelcontextprotocol/modelcontextprotocol",
        "type": "opensource"
      },
      {
        "title": "Protocolo de Contexto del Modelo",
        "url": "https://modelcontextprotocol.io/introduction",
        "type": "article"
      },
      {
        "title": "Referencia de la API de OpenAI",
        "url": "https://platform.openai.com/docs/api-reference",
        "type": "article"
      },
      {
        "title": "Documentación de la API de Anthropic",
        "url": "https://docs.anthropic.com/claude/reference",
        "type": "article"
      }
    ]
  },
  "yv_-87FVM7WKn5iv6LW9q": {
    "title": "Servidores MCP",
    "description": "Un Servidor MCP es la máquina principal o servicio en la nube que ejecuta el Protocolo de Contexto del Modelo. Mantiene la “memoria” compartida que necesitan los diferentes agentes de IA para estar en la misma página. Cuando un agente envía una solicitud, el servidor comprueba quién pregunta, extrae el contexto correcto de su almacén y lo envía rápidamente. También guarda nuevos hechos y resultados de tareas para que el próximo agente pueda usarlos. Un Servidor MCP debe manejar muchos usuarios a la vez, proteger datos privados con reglas de acceso estrictas y registrar cada cambio para facilitar la reversión. Los buenos servidores dividen el trabajo en tareas pequeñas, las distribuyen entre muchas computadoras y agregan copias de seguridad para nunca perder datos. En resumen, el Servidor MCP es el centro que asegura que todos los agentes compartan un contexto fresco, seguro y correcto.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "punkeye/awesome-mcp-servers",
        "url": "https://github.com/punkpeye/awesome-mcp-servers",
        "type": "opensource"
      },
      {
        "title": "Presentamos el Servidor MCP de Azure",
        "url": "https://devblogs.microsoft.com/azure-sdk/introducing-the-azure-mcp-server/",
        "type": "article"
      },
      {
        "title": "La Guía Definitiva de MCP",
        "url": "https://guangzhengli.com/blog/en/model-context-protocol",
        "type": "article"
      },
      {
        "title": "Servidores MCP de AWS para Asistentes de Código",
        "url": "https://aws.amazon.com/blogs/machine-learning/introducing-aws-mcp-servers-for-code-assistants-part-1/",
        "type": "article"
      }
    ]
  },
  "1NXIN-Hbjl5rPy_mqxQYW": {
    "title": "Creación de Servidores MCP",
    "description": "Un servidor MCP almacena y comparte datos de conversación para agentes de IA utilizando el Protocolo de Contexto del Modelo (MCP), un estándar para la gestión de la memoria del agente. Comienza eligiendo un lenguaje y un marco web, luego crea puntos finales REST como `/messages`, `/state` y `/health`. Cada punto final intercambia JSON siguiendo el esquema MCP. Almacena los registros de sesión con un ID de sesión, rol y marca de tiempo utilizando una base de datos o un almacén en memoria. Agrega autenticación basada en tokens y filtros para que los agentes puedan obtener solo lo que necesitan. Establece límites en el tamaño de los mensajes y las tasas de solicitud para evitar la sobrecarga. Finalmente, escribe pruebas unitarias, agrega monitoreo y ejecuta pruebas de carga para garantizar la estabilidad.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Especificación del Protocolo de Contexto del Modelo (MCP)",
        "url": "https://www.anthropic.com/news/model-context-protocol",
        "type": "article"
      },
      {
        "title": "¿Cómo Construir y Alojar tus Propios Servidores MCP en Pasos Sencillos?",
        "url": "https://collabnix.com/how-to-build-and-host-your-own-mcp-servers-in-easy-steps/",
        "type": "article"
      }
    ]
  },
  "iBtJp24F_kJE3YlBsW60s": {
    "title": "Escritorio Local",
    "description": "Una implementación de Escritorio Local significa ejecutar el servidor MCP directamente en tu propia computadora en lugar de una nube o servidor remoto. Instalas el software MCP, los tiempos de ejecución necesarios y los archivos del modelo en tu computadora de escritorio o portátil. Luego, el servidor escucha en una dirección local como `127.0.0.1:8000`, accesible solo desde la misma máquina a menos que abras los puertos manualmente. Esta configuración es ideal para pruebas rápidas, demostraciones personales o experimentos privados, ya que mantienes el control total y evitas los costos de la nube. Sin embargo, está limitado por la velocidad y la memoria de tu hardware, y otros no pueden acceder a él sin herramientas de tunelización como ngrok o reenvío de puertos local.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Construye un Servidor MCP Local Simple",
        "url": "https://blog.stackademic.com/build-simple-local-mcp-server-5434d19572a4",
        "type": "article"
      },
      {
        "title": "Cómo Construir y Alojar tus Propios Servidores MCP en Pasos Sencillos",
        "url": "https://collabnix.com/how-to-build-and-host-your-own-mcp-servers-in-easy-steps/",
        "type": "article"
      },
      {
        "title": "Expón localhost a Internet",
        "url": "https://ngrok.com/docs",
        "type": "article"
      },
      {
        "title": "Ejecuta un Servidor Local en tu Máquina",
        "url": "https://www.youtube.com/watch?v=ldGl6L4Vktk",
        "type": "video"
      }
    ]
  },
  "dHNMX3_t1KSDdAWqgdJXv": {
    "title": "Remoto / Nube",
    "description": "La implementación remota o en la nube coloca el servidor MCP en un proveedor de nube en lugar de una máquina local. Empaquetas el servidor como un contenedor o máquina virtual, eliges un servicio como AWS, Azure o GCP, y le das cómputo, almacenamiento y una dirección HTTPS pública. Un equilibrador de carga distribuye el tráfico, mientras que el autoescalado agrega o elimina copias del servidor según cambie la demanda. Aseguras el punto final con TLS, claves API y firewalls, y envías registros y métricas a las herramientas de monitoreo del proveedor. Esta configuración permite que el servidor maneje muchos usuarios, las actualizaciones son más fáciles y evitas los límites del hardware local, aunque debes vigilar los costos y proteger los datos confidenciales.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "IA en el Borde vs. IA en la Nube: Modelos de Inteligencia en Tiempo Real",
        "url": "https://medium.com/@hassaanidrees7/edge-ai-vs-cloud-ai-real-time-intelligence-vs-centralized-processing-df8c6e94fd11",
        "type": "article"
      },
      {
        "title": "IA en la Nube vs. IA Local",
        "url": "https://www.pluralsight.com/resources/blog/ai-and-data/ai-on-premises-vs-in-cloud",
        "type": "article"
      },
      {
        "title": "Implementación de IA en la Nube vs Local",
        "url": "https://toxigon.com/cloud-vs-on-premises-ai-deployment",
        "type": "article"
      }
    ]
  },
  "qwdh5pkBbrF8LKPxbZp4F": {
    "title": "Cadena de Pensamiento (CoT)",
    "description": "La Cadena de Pensamiento (CoT) es una forma en que un agente de IA piensa en voz alta. Antes de dar su respuesta final, el agente escribe notas breves que muestran cada paso que toma. Estas notas pueden enumerar hechos, nombrar subtareas o realizar pequeños cálculos matemáticos. Al ver los pasos, el agente se mantiene organizado y es menos probable que cometa un error. Las personas que leen la respuesta también pueden verificar la lógica y detectar cualquier punto débil. Los mismos pasos escritos se pueden retroalimentar al agente para que pueda planificar, reflexionar o corregirse a sí mismo. Debido a que es fácil de usar y aumenta la confianza, CoT es uno de los diseños más comunes para los agentes basados en lenguaje en la actualidad.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "El Prompting de Cadena de Pensamiento Suscita el Razonamiento en Modelos de Lenguaje Grandes",
        "url": "https://arxiv.org/abs/2201.11903",
        "type": "article"
      },
      {
        "title": "Evocando el Razonamiento de Cadena de Pensamiento en LLMs - Guía de Prompting",
        "url": "https://www.promptingguide.ai/techniques/cot",
        "type": "article"
      }
    ]
  },
  "cW8O4vLLKEG-Q0dE8E5Zp": {
    "title": "Agente RAG",
    "description": "Un agente RAG (Generación Aumentada por Recuperación) mezcla la búsqueda con la generación de lenguaje para poder responder preguntas utilizando hechos frescos y confiables. Cuando un usuario envía una consulta, el agente primero convierte esa consulta en una incrustación, básicamente una lista de números que captura su significado. Luego busca incrustaciones similares en una base de datos vectorial que contiene pasajes de páginas web, PDF u otro texto. Los pasajes que mejor coinciden regresan como contexto. El agente coloca la pregunta original y esos pasajes en un modelo de lenguaje grande. El modelo escribe la respuesta final, basando cada oración en el texto recuperado. Esta configuración mantiene el modelo más pequeño, reduce las conjeturas incorrectas y permite que el sistema actualice su conocimiento simplemente agregando nuevos documentos a la base de datos. Las herramientas comunes para construir un agente RAG incluyen un modelo de incrustación, un almacén de vectores como FAISS o Pinecone, y un LLM conectado a través de un marco como LangChain o LlamaIndex.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "¿Qué es RAG? - Explicación de la IA de Generación Aumentada por Recuperación",
        "url": "https://aws.amazon.com/what-is/retrieval-augmented-generation/",
        "type": "article"
      },
      {
        "title": "¿Qué es la Generación Aumentada por Recuperación, también conocida como RAG?",
        "url": "https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/",
        "type": "article"
      }
    ]
  },
  "6YLCMWzystao6byCYCTPO": {
    "title": "Planificador Ejecutor",
    "description": "Un **agente planificador-ejecutor** es un tipo de agente de IA que divide su trabajo en dos partes claras: planificación y ejecución. El **planificador** piensa con anticipación, tomando un objetivo y dividiéndolo en una secuencia de pasos, ordenándolos de manera lógica y eficiente. El **ejecutor**, por otro lado, toma cada paso planificado y lo lleva a cabo, monitoreando los resultados e informando al planificador. Si algo falla o el mundo cambia, el planificador puede actualizar el plan y el ejecutor sigue los nuevos pasos. Este enfoque modular permite al agente manejar tareas complejas dividiéndolas en partes manejables, lo que facilita la depuración, la reutilización de planes y el mantenimiento de un comportamiento claro y consistente.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Agentes de Planificación y Ejecución",
        "url": "https://blog.langchain.dev/planning-agents/",
        "type": "article"
      },
      {
        "title": "Planificar y Ejecutar: Arquitectura de Agentes de IA",
        "url": "https://medium.com/@shubham.ksingh.cer14/plan-and-execute-ai-agents-architecture-f6c60b5b9598",
        "type": "article"
      }
    ]
  },
  "Ep8RoZSy_Iq_zWXlGQLZo": {
    "title": "Agentes DAG",
    "description": "Un agente DAG (Grafo Acíclico Dirigido) está hecho de pequeñas partes llamadas nodos que forman un grafo unidireccional sin bucles. Cada nodo realiza una tarea y pasa su resultado al siguiente. Como no hay ciclos, los datos siempre avanzan, lo que facilita el seguimiento y la depuración de los flujos de trabajo. Los nodos independientes pueden ejecutarse en paralelo, acelerando las tareas. Si un nodo falla, puedes rastrear y corregir esa parte sin tocar el resto. Los agentes DAG son ideales para trabajos como la limpieza de datos, el razonamiento de varios pasos o los flujos de trabajo donde no se necesita retroceder.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Airflow: Documentación de Grafos Acíclicos Dirigidos",
        "url": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html",
        "type": "article"
      },
      {
        "title": "¿Qué son los DAGs en los Sistemas de IA?",
        "url": "https://www.restack.io/p/version-control-for-ai-answer-what-is-dag-in-ai-cat-ai",
        "type": "article"
      },
      {
        "title": "DAGs Explicados de Forma Sencilla",
        "url": "https://www.youtube.com/watch?v=1Yh5S-S6wsI",
        "type": "video"
      }
    ]
  },
  "Nmy1PoB32DcWZnPM8l8jT": {
    "title": "Árbol del Pensamiento",
    "description": "El Árbol del Pensamiento es una forma de organizar el razonamiento de un agente de IA como un árbol ramificado. En la raíz, el agente enuncia el problema principal. Cada rama es una pequeña idea, paso o suposición que podría conducir a una solución. El agente expande las ramas más prometedoras, comprueba si tienen sentido y poda los caminos que parecen incorrectos o inútiles. Esta configuración ayuda al agente a explorar muchas respuestas posibles mientras se mantiene enfocado en las mejores. Como el agente puede comparar diferentes ramas lado a lado, es menos probable que se atasque en una mala línea de pensamiento. El resultado es una resolución de problemas más confiable y creativa.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Árbol de Pensamientos (ToT) | Guía de Ingeniería de Prompts",
        "url": "https://www.promptingguide.ai/techniques/tot",
        "type": "article"
      },
      {
        "title": "¿Qué es el árbol de pensamientos? - IBM",
        "url": "https://www.ibm.com/think/topics/tree-of-thoughts",
        "type": "article"
      },
      {
        "title": "El Enfoque Revolucionario del Prompting de Árbol de Pensamiento en IA",
        "url": "https://medium.com/@WeavePlatform/the-revolutionary-approach-of-tree-of-thought-prompting-in-ai-eb7c0872247b",
        "type": "article"
      }
    ]
  },
  "US6T5dXM8IY9V2qZnTOFW": {
    "title": "Manual (desde cero)",
    "description": "Construir un agente de IA desde cero significa escribir cada parte del sistema tú mismo, sin bibliotecas prefabricadas. Defines cómo el agente percibe las entradas, almacena la memoria, toma decisiones y aprende con el tiempo. Primero, eliges un objetivo claro, como resolver acertijos o chatear. Luego codificas las entradas (teclado, mouse, texto), la lógica de decisión (reglas o redes neuronales) y la memoria (guardando hechos de eventos pasados). Las pruebas son críticas: ejecutas el agente, observas sus acciones, depuras y mejoras. Aunque lleva más tiempo, este enfoque brinda una comprensión profunda y un control total sobre cómo funciona y evoluciona el agente.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Una Guía Paso a Paso para Construir un Agente de IA Desde Cero",
        "url": "https://www.neurond.com/blog/how-to-build-an-ai-agent",
        "type": "article"
      },
      {
        "title": "Cómo Construir Agentes de IA",
        "url": "https://wotnot.io/blog/build-ai-agents",
        "type": "article"
      },
      {
        "title": "Construye tu Propio Agente de IA desde Cero en 30 Minutos",
        "url": "https://medium.com/@gurpartap.sandhu3/build-you-own-ai-agent-from-scratch-in-30-mins-using-simple-python-1458f8099da0",
        "type": "article"
      },
      {
        "title": "Construyendo un Agente de IA Desde Cero",
        "url": "https://www.youtube.com/watch?v=bTMPwUgLZf0",
        "type": "video"
      }
    ]
  },
  "aafZxtjxiwzJH1lwHBODi": {
    "title": "LLM Nativo \"Llamada de Función\"",
    "description": "La “llamada de función” nativa de LLM permite que un modelo de lenguaje grande decida cuándo ejecutar un fragmento de código y qué entradas pasarle. Primero le dices al modelo qué funciones están disponibles. Para cada una, das un nombre corto, una descripción breve y una lista de argumentos con sus tipos. Durante un chat, el modelo puede responder en JSON que coincida con este esquema en lugar de texto sin formato. Tu programa contenedor lee el JSON, llama a la función real y luego retroalimenta el resultado al modelo para que pueda continuar. Este bucle ayuda a un agente a buscar en la web, buscar datos, enviar un correo electrónico o realizar cualquier otra tarea que expongas. Debido a que la salida está estructurada, obtienes menos errores que cuando el modelo intenta escribir código sin procesar o comandos en lenguaje natural.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Una Guía Completa para la Llamada de Funciones en LLMs",
        "url": "https://thenewstack.io/a-comprehensive-guide-to-function-calling-in-llms/",
        "type": "article"
      },
      {
        "title": "Llamada de Funciones con LLMs | Guía de Ingeniería de Prompts",
        "url": "https://www.promptingguide.ai/applications/function_calling",
        "type": "article"
      },
      {
        "title": "Llamada de Funciones con LLMs de Código Abierto",
        "url": "https://medium.com/@rushing_andrei/function-calling-with-open-source-llms-594aa5b3a304",
        "type": "article"
      }
    ]
  },
  "AQtxTTxmBpfl8BMgJbGzc": {
    "title": "Llamada de Funciones de OpenAI",
    "description": "La Llamada de Funciones de OpenAI te permite darle a un modelo de lenguaje una lista de herramientas y hacer que decida cuál usar y con qué datos. Describes cada herramienta con un nombre corto, qué hace y la forma de sus entradas en un pequeño esquema similar a JSON. Luego pasas el mensaje del usuario y esta lista de herramientas al modelo. En lugar de texto normal, el modelo puede responder con un bloque JSON que nombra la herramienta y completa los argumentos necesarios. Tu programa lee este bloque, ejecuta la función real y puede enviar el resultado de vuelta para el siguiente paso. Este patrón hace que las acciones del agente sean claras, fáciles de analizar y difíciles de abusar, porque el modelo no puede ejecutar código por sí solo y todas las llamadas pasan por tus controles. También reduce los hacks de prompts y los formatos incorrectos, por lo que los agentes funcionan más rápido y de forma más segura.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Documentación de OpenAI – Llamada de Funciones",
        "url": "https://platform.openai.com/docs/guides/function-calling",
        "type": "article"
      },
      {
        "title": "Libro de Recetas de OpenAI – Uso de Funciones con Modelos GPT",
        "url": "https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb",
        "type": "article"
      },
      {
        "title": "Blog de @officialOpenAI – Anuncio de Llamada de Funciones y Otras Actualizaciones",
        "url": "https://openai.com/blog/function-calling-and-other-api-updates",
        "type": "article"
      },
      {
        "title": "Referencia de la API de @officialOpenAI – Sección de Funciones",
        "url": "https://platform.openai.com/docs/api-reference/chat/create#functions",
        "type": "article"
      },
      {
        "title": "Comunidad de @officialOpenAI – Discusiones y Ejemplos sobre Llamada de Funciones",
        "url": "https://community.openai.com/tag/function-calling",
        "type": "article"
      }
    ]
  },
  "_iIsBJTVS6OBf_dsdmbVO": {
    "title": "Llamada de Función de Gemini",
    "description": "La llamada de función de Gemini te permite conectar el modelo de lenguaje Gemini a código real de una manera segura y sencilla. Primero listas las funciones que quieres que use, cada una con un nombre, una nota breve sobre lo que hace y un esquema JSON para los argumentos necesarios. Cuando el usuario habla, Gemini revisa esta lista y, si una coincidencia tiene sentido, responde con un pequeño bloque JSON que contiene el nombre de la función elegida y los argumentos completados. Tu programa luego ejecuta esa función, envía el resultado de vuelta y el chat continúa. Debido a que la respuesta es JSON estricto y no texto libre, no tienes que adivinar lo que el modelo quiere decir y evitas muchos errores. Este flujo te permite construir agentes que extraen datos, llaman a API o llevan a cabo largas cadenas de acciones mientras mantienes el control de la lógica de negocio de tu lado.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Llamada de Función con la API de Gemini",
        "url": "https://ai.google.dev/gemini-api/docs/function-calling",
        "type": "article"
      },
      {
        "title": "Comprendiendo la Llamada de Función в Gemini",
        "url": "https://medium.com/google-cloud/understanding-function-calling-in-gemini-3097937f1905",
        "type": "article"
      }
    ]
  },
  "37GBFVZ2J2d5r8bd1ViHq": {
    "title": "API de Asistentes de OpenAI",
    "description": "La API de Asistentes de OpenAI te permite agregar acciones claras y específicas de la tarea a un chat con un modelo de lenguaje grande. Primero describes cada acción que quieres que el modelo use, dándole un nombre, un propósito breve y una lista de entradas en formato JSON. Durante el chat, el modelo puede decidir que una de estas acciones ayudará. Luego devuelve el nombre de la acción y un objeto JSON con los valores de entrada que cree correctos. Tu código recibe esta llamada, ejecuta trabajo real como una consulta de base de datos o una solicitud web, y envía el resultado de vuelta al modelo. El modelo lee el resultado y continúa el chat, ahora armado con hechos frescos. Este bucle te permite mantener el control de qué trabajo real sucede mientras sigues dejando que el modelo planifique y hable en lenguaje natural.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Documentación de OpenAI – Descripción General de la API de Asistentes",
        "url": "https://platform.openai.com/docs/assistants/overview",
        "type": "article"
      },
      {
        "title": "Blog de OpenAI – Presentación de la API de Asistentes",
        "url": "https://openai.com/blog/assistants-api",
        "type": "article"
      },
      {
        "title": "Libro de Recetas de OpenAI – Ejemplo de la API de Asistentes",
        "url": "https://github.com/openai/openai-cookbook/blob/main/examples/Assistants_API_overview_python.ipynb",
        "type": "article"
      },
      {
        "title": "Referencia de la API de OpenAI – Puntos Finales de Asistentes",
        "url": "https://platform.openai.com/docs/api-reference/assistants",
        "type": "article"
      }
    ]
  },
  "Ka6VpCEnqABvwiF9vba7t": {
    "title": "Langchain",
    "description": "LangChain es una biblioteca de Python y JavaScript que te ayuda a poner a trabajar modelos de lenguaje grandes en productos reales. Proporciona partes listas para usar para tareas comunes de agentes, como hablar con muchas herramientas, mantener memoria a corto plazo y llamar a una API externa cuando el modelo necesita datos frescos. Combinas estas partes como bloques de Lego: eliges un modelo, agregas una plantilla de prompt, encadenas los pasos y luego envuelves la cadena en un “agente” que puede elegir qué paso ejecutar a continuación. Los conectores incorporados se vinculan a OpenAI, Hugging Face, almacenes de vectores y bases de datos SQL, para que puedas buscar documentos o extraer datos de la empresa sin escribir mucho código de unión. Esto te permite pasar rápidamente de la idea al bot funcional, sin dejar de permitirte intercambiar partes si tus necesidades cambian.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "langchain-ai/langchain",
        "url": "https://github.com/langchain-ai/langchain",
        "type": "opensource"
      },
      {
        "title": "Documentación de LangChain",
        "url": "https://python.langchain.com/docs/introduction/",
        "type": "article"
      },
      {
        "title": "Construyendo Aplicaciones con LLMs usando LangChain",
        "url": "https://www.pinecone.io/learn/series/langchain/",
        "type": "article"
      },
      {
        "title": "Agentes de IA con LangChain y LangGraph",
        "url": "https://www.udacity.com/course/ai-agents-with-langchain-and-langgraph--cd13764",
        "type": "article"
      },
      {
        "title": "Curso Intensivo de LangChain - Construye Aplicaciones LLM Rápidamente (YouTube)",
        "url": "https://www.youtube.com/watch?v=nAmC7SoVLd8",
        "type": "video"
      }
    ]
  },
  "iEHF-Jm3ck-Iu85EbCoDi": {
    "title": "LlamaIndex",
    "description": "LlamaIndex es un conjunto de herramientas de Python de código abierto que te ayuda a dar acceso a un modelo de lenguaje a tus propios datos. Cargas archivos como PDF, páginas web o filas de bases de datos. El conjunto de herramientas divide el texto en fragmentos, los convierte en vectores y los almacena en un almacén de vectores elegido como FAISS o Pinecone. Cuando un usuario hace una pregunta, LlamaIndex encuentra los mejores fragmentos, los agrega al prompt y envía el prompt al modelo. Este flujo se llama generación aumentada por recuperación y permite que un agente dé respuestas basadas en tu contenido. La biblioteca ofrece clases simples para cargar, indexar, consultar y componer herramientas, por lo que escribes menos código repetitivo. También funciona con otros marcos, incluido LangChain, y admite modelos de OpenAI o Hugging Face. Con unas pocas líneas de código puedes construir un chatbot, un sistema de preguntas y respuestas u otro agente que conozca tus documentos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "run-llama/llama_index",
        "url": "https://github.com/run-llama/llama_index",
        "type": "opensource"
      },
      {
        "title": "LlamaIndex",
        "url": "https://llamaindex.ai/",
        "type": "article"
      },
      {
        "title": "Documentación de LlamaIndex",
        "url": "https://docs.smith.langchain.com/",
        "type": "article"
      },
      {
        "title": "¿Qué es LlamaIndex.TS?",
        "url": "https://ts.llamaindex.ai/docs/llamaindex",
        "type": "article"
      },
      {
        "title": "¿Qué es LlamaIndex? - IBM",
        "url": "https://www.ibm.com/think/topics/llamaindex",
        "type": "article"
      },
      {
        "title": "LlamaIndex - Hugging Face",
        "url": "https://huggingface.co/llamaindex",
        "type": "article"
      }
    ]
  },
  "XS-FsvtrXGZ8DPrwOsnlI": {
    "title": "Haystack",
    "description": "Haystack es un marco de Python de código abierto que te ayuda a construir rápidamente agentes de búsqueda y respuesta a preguntas. Conectas tus fuentes de datos, eliges un modelo de lenguaje y configuras canalizaciones que encuentran la mejor respuesta a la consulta de un usuario. Haystack maneja tareas como la indexación de documentos, la recuperación de pasajes, la ejecución del modelo y la clasificación de resultados. Funciona con muchos back-ends como Elasticsearch, OpenSearch, FAISS y Pinecone, por lo que puedes escalar desde una computadora portátil hasta un clúster. Puedes agregar funciones como resumen, traducción y chat de documentos agregando nodos adicionales a la canalización. El marco también ofrece API REST, una interfaz de usuario web y tutoriales claros, lo que facilita la prueba e implementación de tu agente en producción.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "deepset-ai/haystack",
        "url": "https://github.com/deepset-ai/haystack",
        "type": "opensource"
      },
      {
        "title": "Haystack",
        "url": "https://haystack.deepset.ai/",
        "type": "article"
      },
      {
        "title": "Descripción General de Haystack",
        "url": "https://docs.haystack.deepset.ai/docs/intro",
        "type": "article"
      }
    ]
  },
  "7YtnQ9-KIvGPSpDzEDexl": {
    "title": "AutoGen",
    "description": "AutoGen es un marco de Python de código abierto que te ayuda a construir agentes de IA sin empezar desde cero. Te permite definir cada agente con un rol, objetivos y herramientas, luego maneja el flujo de chat entre ellos y un modelo de lenguaje grande como GPT-4. Puedes encadenar varios agentes para que planifiquen, codifiquen, revisen y ejecuten tareas juntos. La biblioteca incluye módulos listos para usar para memoria, planificación de tareas, llamada a herramientas y ejecución de funciones, por lo que solo escribes las partes que son únicas para tu aplicación. AutoGen se conecta a OpenAI, Azure o modelos locales a través de un archivo de configuración simple. Los registros, el seguimiento de costos y la depuración paso a paso vienen incorporados, lo que facilita las pruebas. Debido a que los agentes son objetos simples de Python, puedes mezclarlos con otras bibliotecas o tu propio código. AutoGen aún es joven, así que espera cambios rápidos y mantén un ojo en los costos de uso, pero es una opción sólida cuando quieres convertir un prompt en un sistema multiagente funcional en horas en lugar de semanas.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "GitHub - microsoft/autogen",
        "url": "https://github.com/microsoft/autogen",
        "type": "opensource"
      },
      {
        "title": "AutoGen - Microsoft Research",
        "url": "https://www.microsoft.com/en-us/research/project/autogen/",
        "type": "article"
      }
    ]
  },
  "uFPJqgU4qGvZyxTv-osZA": {
    "title": "CrewAI",
    "description": "CrewAI es un marco de Python de código abierto para crear equipos de agentes de IA, llamados una cuadrilla. A cada agente se le asigna un nombre, un rol y un conjunto de herramientas, y el sistema gestiona la planificación, la comunicación y la ejecución entre ellos. Para usarlo, instala el paquete, define los agentes en el código, conéctalos con un objeto `Crew` y asigna un prompt de misión. CrewAI interactúa con un LLM como GPT-4 o Claude, pasa mensajes, ejecuta herramientas y devuelve una salida final. También puedes agregar búsqueda web, funciones personalizadas o almacenes de memoria. Los registros están incorporados para ayudar a depurar y optimizar los flujos de trabajo.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "CrewAI",
        "url": "https://crewai.com/",
        "type": "article"
      },
      {
        "title": "Documentación de CrewAI",
        "url": "https://docs.crewai.com/",
        "type": "article"
      },
      {
        "title": "Primeros Pasos con CrewAI: Construyendo Agentes de IA que Trabajan Juntos",
        "url": "https://medium.com/@cammilo/getting-started-with-crewai-building-ai-agents-that-work-together-9c1f47f185ca",
        "type": "article"
      },
      {
        "title": "Tutorial Completo de Crew AI para Principiantes",
        "url": "https://www.youtube.com/watch?v=q6QLGS306d0",
        "type": "video"
      }
    ]
  },
  "eWxQiBrxIUG2JNcrdfIHS": {
    "title": "Smol Depot",
    "description": "Smol Depot es un kit de código abierto que te permite agrupar todas las partes de un pequeño agente de IA en un solo lugar. Mantienes los prompts, la configuración y los archivos de código juntos en una sola carpeta, luego apuntas la herramienta Depot a esa carpeta para iniciar el agente. La herramienta maneja tareas como cargar modelos, guardar el historial de chat y llamar a API externas, para que no tengas que escribir ese código de unión tú mismo. Un simple comando puede copiar una plantilla de inicio, permitiéndote concentrarte en la lógica y los prompts que hacen especial a tu agente. Como todo reside en archivos de texto sin formato, puedes rastrear los cambios con Git y compartir el agente como cualquier otro proyecto.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "smol.ai - Plataforma de Ajuste Fino Continuo para Ingenieros de IA",
        "url": "https://smol.candycode.dev/",
        "type": "article"
      },
      {
        "title": "Tutorial de Smol AI de 5 Minutos",
        "url": "https://www.ai-jason.com/learning-ai/smol-ai-tutorial",
        "type": "article"
      },
      {
        "title": "Curso Completo de Smol AI para Principiantes",
        "url": "https://www.youtube.com/watch?v=d7qFVrpLh34",
        "type": "video"
      }
    ]
  },
  "1EZFbDHA5J5_5BPMLMxXb": {
    "title": "Uso de Herramientas de Anthropic",
    "description": "El Uso de Herramientas de Anthropic te permite conectar un modelo Claude a funciones de software reales para que el agente pueda realizar tareas útiles por sí solo. Le das a Claude una lista de herramientas, cada una con un nombre, una breve descripción y un esquema JSON estricto que muestra los campos de entrada permitidos. Durante un chat, envías texto de usuario más esta lista de herramientas. Claude decide si se debe ejecutar una herramienta, elige una y devuelve un bloque JSON que coincide con el esquema. Tu código lee el JSON, llama a la función correspondiente y envía el resultado de vuelta a Claude para el siguiente paso. Este bucle se repite hasta que no se necesiten más llamadas a herramientas. Esquemas claros, conjuntos de campos pequeños y ejemplos útiles hacen que las llamadas sean precisas. Al mantener el modelo a cargo de elegir las herramientas mientras tu código controla las acciones reales, obtienes flexibilidad y seguridad.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Uso de Herramientas de Anthropic",
        "url": "https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview",
        "type": "article"
      }
    ]
  },
  "v8qLnyFRnEumodBYxQSXQ": {
    "title": "Métricas a Seguir",
    "description": "Para juzgar qué tan bien funciona un agente de IA, necesitas números claros. Realiza un seguimiento de la exactitud, precisión, exhaustividad y puntuación F1 para medir la corrección. Para tareas de clasificación, utiliza métricas como la precisión media promedio o ROC-AUC. Si los usuarios interactúan con el agente, monitorea el tiempo de respuesta, la latencia y las tasas de falla. Las métricas de seguridad cuentan los resultados tóxicos o sesgados, mientras que las pruebas de robustez verifican cómo maneja el agente las entradas desordenadas o complicadas. Las métricas de recursos (memoria, CPU y energía) muestran si puede escalar. Elige las métricas que coincidan con tu objetivo, compáralas con una línea de base y realiza un seguimiento de las tendencias entre versiones.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Pruebas de Robustez para IA",
        "url": "https://mitibmwatsonailab.mit.edu/category/robustness/",
        "type": "article"
      },
      {
        "title": "Guía Completa de Métricas de Evaluación de Aprendizaje Automático",
        "url": "https://medium.com/analytics-vidhya/complete-guide-to-machine-learning-evaluation-metrics-615c2864d916",
        "type": "article"
      },
      {
        "title": "Midiendo el Rendimiento del Modelo",
        "url": "https://developers.google.com/machine-learning/crash-course/classification/accuracy",
        "type": "article"
      },
      {
        "title": "Un Marco Práctico para la Medición del Valor de la IA (Gen)AI",
        "url": "https://medium.com/google-cloud/a-practical-framework-for-gen-ai-value-measurement-5fccf3b66c43",
        "type": "article"
      }
    ]
  },
  "qo_O4YAe4-MTP_ZJoXJHR": {
    "title": "Pruebas Unitarias para Herramientas Individuales",
    "description": "Las pruebas unitarias verifican que cada herramienta que utiliza un agente de IA funcione como se espera cuando está sola. Escribes pruebas pequeñas que alimentan la herramienta con una entrada clara y luego comparas su salida con una respuesta correcta conocida. Si la herramienta es una función que analiza fechas, pruebas muchas cadenas de fechas y ves si la función da los resultados correctos. Las buenas pruebas cubren casos normales, casos límite y casos de error. Ejecuta las pruebas cada vez que cambies el código. Cuando una prueba falla, corrige la herramienta antes de continuar. Este hábito evita que los errores se propaguen a flujos de trabajo de agentes más grandes y acelera la depuración posterior.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Pruebas Unitarias de Agentes",
        "url": "https://docs.patronus.ai/docs/agent_evals/unit_testing",
        "type": "article"
      },
      {
        "title": "Las Mejores Herramientas de IA para Pruebas Unitarias: Un Vistazo a las 14 Mejores Herramientas de IA",
        "url": "https://thetrendchaser.com/best-ai-tools-for-unit-testing/",
        "type": "article"
      },
      {
        "title": "IA para Pruebas Unitarias: Revolucionando la Productividad del Desarrollador",
        "url": "https://www.diffblue.com/resources/ai-for-unit-testing-revolutionizing-developer-productivity/",
        "type": "article"
      }
    ]
  },
  "P9-SiIda3TSjHsfkI5OUV": {
    "title": "Pruebas de Integración para Flujos",
    "description": "Las pruebas de integración para flujos verifican que un agente de IA funcione bien desde la primera entrada del usuario hasta la acción final, a través de cada paso intermedio. Une todas las partes del sistema —comprensión del lenguaje natural, planificación, memoria, herramientas y salida— y las ejecuta juntas en escenarios reales. Los casos de prueba siguen rutas comunes y de casos límite que un usuario podría tomar. El objetivo es detectar errores que solo aparecen cuando las partes interactúan, como datos incorrectos pasados entre módulos o problemas de temporización. Las buenas prácticas incluyen la creación de conjuntos de pruebas automatizadas, el uso de servicios reales o simulados y el registro de cada paso para facilitar la depuración. Cuando las pruebas de integración pasan, ganas confianza en que todo el flujo se siente fluido y confiable para los usuarios.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Pruebas de Integración para Funciones Basadas en IA con Humanos",
        "url": "https://www.microsoft.com/en-us/research/publication/hint-integration-testing-for-ai-based-features-with-humans-in-the-loop/",
        "type": "article"
      },
      {
        "title": "Pruebas de Integración y Pruebas Unitarias en IA",
        "url": "https://www.aviator.co/blog/integration-testing-and-unit-testing-in-the-age-of-ai/",
        "type": "article"
      },
      {
        "title": "Pruebas de Integración",
        "url": "https://www.guru99.com/integration-testing.html",
        "type": "article"
      }
    ]
  },
  "rHxdxN97ZcU7MPl8L1jzN": {
    "title": "Evaluación Humana en el Bucle",
    "description": "La evaluación humana en el bucle verifica un agente de IA permitiendo que personas reales juzguen su salida y comportamiento. En lugar de confiar solo en puntuaciones automatizadas, los probadores invitan a usuarios, expertos en el dominio o trabajadores de crowdsourcing a observar tareas, etiquetar respuestas, marcar errores y calificar la claridad, equidad o seguridad. Sus comentarios muestran problemas que los números por sí solos omiten, como sesgos ocultos, lenguaje confuso o acciones que una persona considera incorrectas. Los equipos estudian estas notas, ajustan el modelo y ejecutan otra ronda, repitiendo hasta que el agente cumpla con los objetivos de calidad y confianza. Mezclar el juicio humano con los datos conduce a un sistema más preciso, útil y seguro para el uso diario.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Humano en el Bucle · Agentes de Cloudflare",
        "url": "https://developers.cloudflare.com/agents/concepts/human-in-the-loop/",
        "type": "article"
      },
      {
        "title": "¿Qué es Humano en el Bucle?: Una Guía",
        "url": "https://logifusion.com/what-is-human-in-the-loop-htil/",
        "type": "article"
      },
      {
        "title": "ML con Humano en el Bucle",
        "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/sms-human-review-workflow.html",
        "type": "article"
      },
      {
        "title": "La Importancia de la Retroalimentación Humana en la IA (Blog de Hugging Face)",
        "url": "https://huggingface.co/blog/rlhf",
        "type": "article"
      }
    ]
  },
  "xp7TCTRE9HP60_rGzTUF6": {
    "title": "LangSmith",
    "description": "LangSmith es una herramienta que te ayuda a ver qué tan bien funcionan tus agentes de IA. Te permite registrar cada paso que da el agente, desde la primera entrada hasta la respuesta final. Puedes reproducir estos pasos para encontrar lugares donde el agente se equivoca. LangSmith también te permite crear conjuntos de pruebas con prompts de usuarios reales y comparar nuevas versiones del modelo con ellos. Muestra números claros sobre velocidad, costo y precisión para que puedas detectar compensaciones. Como LangSmith se vincula a LangChain, puedes agregarlo con solo unas pocas líneas de código adicionales. El panel web luego ofrece gráficos, registros de errores y vistas de resultados lado a lado. Esto facilita el seguimiento del progreso, la corrección de errores y la demostración de que tu agente está mejorando con el tiempo.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "LangSmith",
        "url": "https://smith.langchain.com/",
        "type": "article"
      },
      {
        "title": "Documentación de LangSmith",
        "url": "https://docs.smith.langchain.com/",
        "type": "article"
      },
      {
        "title": "Fortalece tu aplicación con la Evaluación de LangSmith",
        "url": "https://www.langchain.com/evaluation",
        "type": "article"
      },
      {
        "title": "¿Qué es LangSmith y Por Qué Debería Importarme como Desarrollador?",
        "url": "https://medium.com/around-the-prompt/what-is-langsmith-and-why-should-i-care-as-a-developer-e5921deb54b5",
        "type": "article"
      }
    ]
  },
  "YzEDtGEaMaMWVt0W03HRt": {
    "title": "Ragas",
    "description": "Ragas es una herramienta de código abierto utilizada para verificar qué tan bien funciona un agente de Generación Aumentada por Recuperación (RAG). Le das la pregunta del usuario, los pasajes que el agente extrajo de una base de conocimientos y la respuesta final. Ragas luego califica la respuesta por cosas como corrección, relevancia y si los pasajes citados realmente respaldan las palabras de la respuesta. Utiliza modelos de lenguaje grandes internamente, por lo que no necesitas escribir tus propias reglas de puntuación. Los resultados aparecen en un informe claro que muestra los puntos fuertes y débiles de la canalización. Con esta retroalimentación puedes cambiar los prompts, la configuración del recuperador o las opciones del modelo y ver rápidamente si la calidad mejora. Esto hace que probar los sistemas RAG sea más rápido, repetible y menos basado en conjeturas.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "explodinggradients/ragas",
        "url": "https://github.com/explodinggradients/ragas",
        "type": "opensource"
      },
      {
        "title": "Documentación de Ragas",
        "url": "https://docs.ragas.io/en/latest/",
        "type": "article"
      },
      {
        "title": "Evaluación de Aplicaciones RAG con RAGAs",
        "url": "https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a/n",
        "type": "article"
      }
    ]
  },
  "0924QUH1wV7Mp-Xu0FAhF": {
    "title": "DeepEval",
    "description": "DeepEval es una herramienta de código abierto que te ayuda a probar y calificar las respuestas que da tu agente de IA. Escribes pequeños casos de prueba que muestran una entrada y la respuesta que esperas obtener, o una regla que la respuesta debe seguir. DeepEval ejecuta el agente, comprueba la respuesta con medidas integradas como similitud, precisión o seguridad, y luego marca cada prueba como aprobada o fallida. Puedes agregar tus propias comprobaciones, almacenar pruebas en archivos de código o YAML, y ejecutarlas en una canalización de CI para que cada nueva versión del modelo o prompt reciba la misma auditoría rápida. La retroalimentación rápida facilita la detección de errores, la reducción de alucinaciones y la comparación de diferentes modelos antes de enviarlos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Repositorio de GitHub de DeepEval",
        "url": "https://github.com/confident-ai/deepeval",
        "type": "opensource"
      },
      {
        "title": "DeepEval - El Marco de Evaluación LLM de Código Abierto",
        "url": "https://www.deepeval.com/",
        "type": "article"
      },
      {
        "title": "Evalúa LLMs Eficazmente Usando DeepEval: Una Guía Práctica",
        "url": "https://www.datacamp.com/tutorial/deepeval",
        "type": "article"
      },
      {
        "title": "DeepEval - Marco de Evaluación LLM",
        "url": "https://www.youtube.com/watch?v=ZNs2dCXHlfo",
        "type": "video"
      }
    ]
  },
  "zs6LM8WEnb0ERWpiaQCgc": {
    "title": "Registro estructurado y rastreo",
    "description": "El registro estructurado y el rastreo son formas de registrar lo que hace un agente de IA para que puedas encontrar y solucionar problemas rápidamente. En lugar de volcar texto sin formato, el agente escribe registros en un formato fijo de clave-valor, como tiempo, id_usuario, paso y mensaje. Como cada entrada sigue la misma forma, las herramientas de búsqueda pueden filtrar, ordenar y contar eventos con facilidad. El rastreo vincula esas líneas de registro en una cadena que sigue una solicitud o tarea a través de muchas funciones, hilos o microservicios. Al agregar un ID de rastreo único a cada paso, puedes ver cuánto tiempo tomó cada parte y dónde ocurrieron los errores. Juntos, los registros estructurados y los rastreos ofrecen datos claros y legibles por máquina que ayudan a los desarrolladores a detectar rutas de código lentas, comportamientos inusuales y errores ocultos sin interminables escaneos manuales.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Comprendiendo el Registro Estructurado: Una Guía Completa",
        "url": "https://www.graphapp.ai/blog/understanding-structured-logging-a-comprehensive-guide",
        "type": "article"
      },
      {
        "title": "Registro Estructurado y Registro en la Nube",
        "url": "https://cloud.google.com/logging/docs/structured-logging",
        "type": "article"
      },
      {
        "title": "Mejores Prácticas para el Registro en Aplicaciones de IA",
        "url": "https://www.restack.io/p/best-ai-practices-software-compliance-answer-logging-best-practices-cat-ai",
        "type": "article"
      }
    ]
  },
  "SS8mGqf9wfrNqenIWvN8Z": {
    "title": "LangSmith",
    "description": "LangSmith es una herramienta web que te ayuda a ver y corregir lo que hacen tus agentes de IA. Registra cada llamada que el agente hace a un modelo de lenguaje, la entrada que usó y la respuesta que obtuvo. Puedes reproducir cualquier paso, comparar diferentes prompts, medir costos, velocidad y tasas de error, y etiquetar ejecuciones para facilitar la búsqueda. También te permite almacenar conjuntos de pruebas y ejecutar comprobaciones rápidas para saber si el nuevo código empeora el agente. Al mostrar rastreos y gráficos claros, LangSmith facilita la depuración, mejora y confianza en los sistemas de IA creados con LangChain u otros marcos.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "LangSmith",
        "url": "https://smith.langchain.com/",
        "type": "article"
      },
      {
        "title": "Documentación de LangSmith",
        "url": "https://docs.smith.langchain.com/",
        "type": "article"
      },
      {
        "title": "Fortalece tu aplicación con la Evaluación de LangSmith",
        "url": "https://www.langchain.com/evaluation",
        "type": "article"
      },
      {
        "title": "¿Qué es LangSmith y Por Qué Debería Importarme como Desarrollador?",
        "url": "https://medium.com/around-the-prompt/what-is-langsmith-and-why-should-i-care-as-a-developer-e5921deb54b5",
        "type": "article"
      }
    ]
  },
  "MLxP5N0Vrmwh-kyvNeGXn": {
    "title": "Helicone",
    "description": "Helicone es una herramienta de código abierto que te ayuda a observar y comprender cómo tus agentes de IA hablan con modelos de lenguaje grandes. Envías las llamadas de tu modelo a través del proxy de Helicone, y este registra cada solicitud y respuesta sin cambiar el resultado. Un panel web claro muestra luego registros, latencia, recuento de tokens, tasas de error y costo de cada llamada. Puedes filtrar, buscar y rastrear el recorrido de un solo usuario, lo que facilita la detección de prompts lentos o costos crecientes. Helicone también te permite configurar alertas y compartir rastreos con tu equipo, para que los problemas se solucionen rápidamente y los cambios futuros sean más seguros.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Helicone/helicone",
        "url": "https://github.com/Helicone/helicone",
        "type": "opensource"
      },
      {
        "title": "Helicone",
        "url": "https://www.helicone.ai/",
        "type": "article"
      },
      {
        "title": "Observabilidad LLM de Código Abierto de Helicone",
        "url": "https://docs.helicone.ai/getting-started/quick-start",
        "type": "article"
      }
    ]
  },
  "UoIheaJlShiceafrWALEH": {
    "title": "LangFuse",
    "description": "LangFuse es una herramienta gratuita y de código abierto que te permite observar y depurar agentes de IA mientras se ejecutan. Agregas un pequeño fragmento de código a tu agente y LangFuse comienza a recopilar cada prompt, respuesta del modelo y entrada del usuario. Muestra estos datos como líneas de tiempo ordenadas, para que puedas ver cada paso que da el agente, cuánto cuestan las llamadas y dónde ocurren los errores. Puedes etiquetar ejecuciones, buscarlas y comparar diferentes versiones de prompts para encontrar la que funciona mejor. El panel también realiza un seguimiento del uso de tokens y la latencia, lo que te ayuda a reducir costos y mejorar la velocidad. Como LangFuse almacena datos en tu propia base de datos, mantienes el control total del texto confidencial. Funciona bien con marcos populares como LangChain y puede enviar alertas a Slack o correo electrónico cuando algo se rompe.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "langfuse/langfuse",
        "url": "https://github.com/langfuse/langfuse",
        "type": "opensource"
      },
      {
        "title": "LangFuse",
        "url": "https://langfuse.com/",
        "type": "article"
      },
      {
        "title": "Documentación de LangFuse",
        "url": "https://langfuse.com/docs",
        "type": "article"
      },
      {
        "title": "Langfuse: Plataforma de Ingeniería LLM de Código Abierto",
        "url": "https://www.ycombinator.com/companies/langfuse",
        "type": "article"
      }
    ]
  },
  "7UqPXUzqKYXklnB3x-tsv": {
    "title": "openllmetry",
    "description": "openllmetry es una pequeña biblioteca de Python que facilita observar lo que hace tu agente de IA y qué tan bien está funcionando. Envuelve las llamadas a las API de modelos de lenguaje grandes, almacenes de vectores y otras herramientas, luego envía registros, rastreos y métricas simples a cualquier backend que hable el estándar OpenTelemetry, como Jaeger, Zipkin o Grafana. Agregas una o dos líneas de código al inicio, y la biblioteca captura el texto del prompt, el nombre del modelo, la latencia, el recuento de tokens y los costos cada vez que el agente le pide una respuesta al modelo. Los datos te ayudan a detectar pasos lentos, gastos elevados o respuestas incorrectas, y te permite reproducir rastreos completos para depurar cadenas de agentes. Como sigue OpenTelemetry, puedes mezclar estos rastreos de IA con rastreos de servicios normales y ver todo el flujo en un solo lugar.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "traceloop/openllmetry",
        "url": "https://github.com/traceloop/openllmetry",
        "type": "opensource"
      },
      {
        "title": "Documentación de OpenTelemetry",
        "url": "https://www.traceloop.com/blog/openllmetry",
        "type": "article"
      },
      {
        "title": "¿Qué es OpenLLMetry? - traceloop",
        "url": "https://www.traceloop.com/docs/openllmetry/introduction",
        "type": "article"
      },
      {
        "title": "Usa Traceloop con Python",
        "url": "https://www.traceloop.com/docs/openllmetry/getting-started-python",
        "type": "article"
      }
    ]
  },
  "SU2RuicMUo8tiAsQtDI1k": {
    "title": "Inyección de Prompts / Jailbreaks",
    "description": "La inyección de prompts, también llamada jailbreak, es un truco que hace que un sistema de IA rompa sus propias reglas. Un atacante esconde palabras o símbolos especiales dentro de texto de apariencia normal. Cuando la IA lee este texto, sigue las instrucciones ocultas en lugar de sus reglas de seguridad. El atacante podría forzar a la IA a revelar datos privados, producir contenido dañino o dar consejos incorrectos. Este riesgo crece cuando la IA habla con otro software o extrae texto de Internet, porque los prompts dañinos pueden colarse sin previo aviso. Buenas defensas incluyen limpiar la entrada del usuario, establecer barreras de protección sólidas dentro del modelo, verificar las salidas en busca de violaciones de políticas y mantener a los humanos en el bucle para tareas de alto riesgo.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Inyección de Prompts vs. Jailbreaking: ¿Cuál es la Diferencia?",
        "url": "https://learnprompting.org/blog/injection_jailbreaking",
        "type": "article"
      },
      {
        "title": "Inyección de Prompts vs Jailbreak de Prompts",
        "url": "https://codoid.com/ai/prompt-injection-vs-prompt-jailbreak-a-detailed-comparison/",
        "type": "article"
      },
      {
        "title": "Cómo los Ataques de Prompts Explotan la GenAI y Cómo Defenderse",
        "url": "https://unit42.paloaltonetworks.com/new-frontier-of-genai-threats-a-comprehensive-guide-to-prompt-attacks/",
        "type": "article"
      }
    ]
  },
  "UVzLGXG6K7HQVHmw8ZAv2": {
    "title": "Sandboxing de Herramientas / Permisos",
    "description": "El sandboxing de herramientas mantiene al agente de IA dentro de una zona segura donde solo puede ejecutar acciones aprobadas y no puede tocar el sistema más amplio. Los permisos establecen reglas claras que dicen qué archivos, redes o comandos puede usar el agente. Juntos detienen errores, filtraciones o abusos al limitar lo que el agente puede alcanzar y hacer. Los desarrolladores otorgan el conjunto más pequeño de derechos, observan la actividad y bloquean cualquier cosa fuera del plan. Si el agente necesita un nuevo acceso, debe preguntar y obtener un permiso nuevo. Esta simple cerca protege los datos del usuario, reduce el daño y genera confianza en el trabajo del agente.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Sandbox de IA | Tecnología de la Información de la Universidad de Harvard",
        "url": "https://www.huit.harvard.edu/ai-sandbox",
        "type": "article"
      },
      {
        "title": "Cómo Configurar Sandboxes de IA para Maximizar la Adopción",
        "url": "https://medium.com/@emilholmegaard/how-to-set-up-ai-sandboxes-to-maximize-adoption-without-compromising-ethics-and-values-637c70626130",
        "type": "article"
      },
      {
        "title": "Sandboxes para IA - La Iniciativa Datasphere",
        "url": "https://www.thedatasphere.org/datasphere-publish/sandboxes-for-ai/",
        "type": "article"
      }
    ]
  },
  "rdlYBJNNyZUshzsJawME4": {
    "title": "Privacidad de Datos + Redacción de PII",
    "description": "Los agentes de IA a menudo procesan texto, imágenes y registros que incluyen datos personales como nombres, números de teléfono o direcciones. Las filtraciones pueden causar fraude, acoso u otros daños, por lo que leyes como el RGPD y la CCPA requieren protecciones estrictas. Un método clave es la redacción de PII: escanear entradas y salidas para encontrar y enmascarar cualquier detalle personal antes de almacenarlo o compartirlo. La redacción utiliza reglas de patrones, aprendizaje automático o ambos. Los equipos también deben mantener registros de auditoría, hacer cumplir los controles de acceso y probar sus flujos de redacción con frecuencia para evitar filtraciones.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Descripción General del Cumplimiento del RGPD",
        "url": "https://gdpr.eu/",
        "type": "article"
      },
      {
        "title": "Protege Datos Confidenciales con Software de Redacción de PII",
        "url": "https://redactor.ai/blog/pii-redaction-software-guide",
        "type": "article"
      },
      {
        "title": "Una Guía Completa sobre la Redacción de PII",
        "url": "https://enthu.ai/blog/what-is-pii-redaction/",
        "type": "article"
      }
    ]
  },
  "EyLo2j8IQsIK91SKaXkmK": {
    "title": "Barreras de Protección contra Sesgos y Toxicidad",
    "description": "Las barreras de protección contra sesgos y toxicidad evitan que un agente de IA dé resultados injustos o dañinos. El sesgo aparece cuando los datos de entrenamiento favorecen a ciertos grupos o puntos de vista. La toxicidad es un lenguaje odioso, violento o grosero. Para detener esto, comienza con datos limpios y equilibrados. Elimina insultos, estereotipos y spam. Agrega ejemplos de muchas voces para que el modelo aprenda patrones justos. Durante el entrenamiento, prueba el modelo con frecuencia y ajusta los pesos o reglas que se inclinen hacia un lado. Después del entrenamiento, implementa filtros que bloqueen palabras tóxicas o marquen respuestas injustas antes de que los usuarios las vean. Mantén registros, ejecuta auditorías y solicita comentarios a los usuarios para detectar nuevos problemas a tiempo. Anota cada paso para que los constructores y usuarios conozcan los límites y riesgos. Estas acciones protegen a las personas, cumplen con las leyes y ayudan a los usuarios a confiar en la IA.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Define las Barreras de Protección del Agente",
        "url": "https://trailhead.salesforce.com/content/learn/modules/agentforce-agent-planning/define-the-agent-guardrails",
        "type": "article"
      },
      {
        "title": "Cómo Construir Agentes de IA Seguros: Mejores Prácticas para Barreras de Protección",
        "url": "https://medium.com/@sahin.samia/how-to-build-safe-ai-agents-best-practices-for-guardrails-and-oversight-a0085b50c022",
        "type": "article"
      }
    ]
  },
  "63nsfJFO1BwjLX_ZVaPFC": {
    "title": "Seguridad + Pruebas de Equipo Rojo",
    "description": "Las Pruebas de Seguridad + Equipo Rojo son la práctica de verificar un agente de IA en busca de comportamientos dañinos o riesgosos antes y después del lanzamiento. El trabajo de seguridad establece reglas, barreras de protección y alarmas para que el agente cumpla con las leyes, mantenga la privacidad de los datos y trate a las personas de manera justa. Las pruebas de equipo rojo envían probadores calificados para que actúen como atacantes o alborotadores. Escriben prompts engañosos, intentan filtrar datos privados, fuerzan resultados sesgados o hacen que el agente dé consejos peligrosos. Cada debilidad que encuentran se registra y se corrige agregando filtros, mejores datos de entrenamiento, límites más estrictos o monitoreo en vivo. Realizar estas pruebas con frecuencia reduce la posibilidad de daños en el mundo real y genera confianza con los usuarios y reguladores.\n\nVisita los siguientes recursos para aprender más:",
    "links": [
      {
        "title": "Visita el Roadmap Dedicado de Pruebas de Equipo Rojo de IA",
        "url": "https://roadmap.sh/ai-red-teaming",
        "type": "article"
      },
      {
        "title": "Mejorando la seguridad de la IA: Perspectivas y lecciones de las pruebas de equipo rojo",
        "url": "https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/01/14/enhancing-ai-safety-insights-and-lessons-from-red-teaming/",
        "type": "article"
      },
      {
        "title": "Pruebas de Seguridad de IA en Ausencia de Regulaciones",
        "url": "https://aisecuritycentral.com/ai-safety-testing/",
        "type": "article"
      },
      {
        "title": "Una Guía para las Pruebas de Equipo Rojo de IA - HiddenLayer",
        "url": "https://hiddenlayer.com/innovation-hub/a-guide-to-ai-red-teaming/",
        "type": "article"
      }
    ]
  }
}